{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "8aca6b7a-179a-47f8-a5b9-14c934077966"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable, Function\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.distributions import Normal\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import scipy.misc as scpm\n",
    "import math\n",
    "import h5py\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from datta.messages.torchhmm import hmm_marginal_likelihood\n",
    "from datta.messages.torchhmm import hmm_sample\n",
    "from time import time\n",
    "import joblib\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "80457456-d198-4c13-9044-4180218d4039"
    }
   },
   "outputs": [],
   "source": [
    "###############\n",
    "## Load data ##\n",
    "###############\n",
    "\n",
    "batch_size=1000\n",
    "n_mice=17\n",
    "h5_temp = h5py.File('whitened_clean_pca.h5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "8773113b-8522-42ac-8414-b8105031ccb3"
    }
   },
   "outputs": [],
   "source": [
    "################################\n",
    "## Get rid of mouse with nans ##\n",
    "################################\n",
    "\n",
    "uuids_all = list(h5_temp.keys())\n",
    "uuids = copy.deepcopy(uuids_all)\n",
    "delete_inds=[]\n",
    "for i in range(len(uuids_all)):\n",
    "   # print(np.sum(np.isnan(h5_temp[uuids_all[i]][:])))\n",
    "    if np.sum(np.isnan(h5_temp[uuids_all[i]][:]))>0:\n",
    "        delete_inds.append(i)\n",
    "for ii in sorted(delete_inds,reverse=True):\n",
    "    del uuids[ii]\n",
    "    \n",
    "for i in range(n_mice):\n",
    "   # print(uuids[i])\n",
    "    if np.sum(np.isnan(h5_temp[uuids[i]][:])) > 0:\n",
    "        print('ERROR: NANS STILL PRESENT')\n",
    "        ver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "06b85194-0ecf-4f35-a1d5-f0c60dcb7c95"
    }
   },
   "outputs": [],
   "source": [
    "############################\n",
    "## CREATE DATA GENERATORS ##\n",
    "############################\n",
    "\n",
    "def data_generator(pca_file, uuids, batch_size,n_mice):\n",
    "    \n",
    "    total_batches=0\n",
    "    n_batches = [None]*n_mice\n",
    "\n",
    "    for i_mouse in range(n_mice):\n",
    "        length_mouse = pca_file[uuids[i_mouse]].shape[0]\n",
    "        n_batches[i_mouse] = np.floor(length_mouse/batch_size)\n",
    "\n",
    "    total_batches = int(np.sum(n_batches))\n",
    "\n",
    "    batch_inds = np.zeros((int(total_batches),2))\n",
    "    i_pos=0\n",
    "    \n",
    "    for i_mouse in range(n_mice):\n",
    "        for i_batch in range(int(n_batches[i_mouse])):\n",
    "            batch_inds[i_pos,0] = i_mouse\n",
    "            batch_inds[i_pos,1] = i_batch\n",
    "            i_pos+=1\n",
    "\n",
    "    loop_vec = np.arange(total_batches)\n",
    "    \n",
    "    \n",
    "    for i_epoch in range(1000):\n",
    "        np.random.shuffle(loop_vec)\n",
    "        for ii in loop_vec:\n",
    "\n",
    "            i_mouse = int(batch_inds[ii,0])\n",
    "            which_batch = int(batch_inds[ii,1])\n",
    "\n",
    "            yield pca_file[uuids[i_mouse]][which_batch*batch_size:(which_batch+1)*batch_size], i_mouse, which_batch #, behavioral_labels[i_mouse][which_bucket][which_batch*batch_size:(which_batch+1)*batch_size],depth[i_mouse][which_bucket][which_batch*batch_size:(which_batch+1)*batch_size],i_mouse,which_bucket,which_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbpresent": {
     "id": "f43d9784-a8ae-467a-b965-cb95e184c588"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901\n"
     ]
    }
   ],
   "source": [
    "# Get number of training batches\n",
    "\n",
    "pca_file = h5_temp\n",
    "total_batches=0\n",
    "n_batches = [None]*n_mice\n",
    "for i_mouse in range(n_mice):\n",
    "    length_mouse = pca_file[uuids[i_mouse]].shape[0]\n",
    "    n_batches[i_mouse] = np.floor(length_mouse/batch_size)\n",
    "total_batches = int(np.sum(n_batches))\n",
    "nb_tng_batches = total_batches\n",
    "print(nb_tng_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "4e629d78-68fe-49e9-a53a-70a4ba3768be"
    }
   },
   "outputs": [],
   "source": [
    "# Create data generator\n",
    "\n",
    "data_gen = data_generator(h5_temp,uuids,batch_size,n_mice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "c63cc508-464e-4a2b-b82d-a7ef3b06756d"
    }
   },
   "outputs": [],
   "source": [
    "def log_sum_exp(value, dim=None, keepdim=False):\n",
    "    \"\"\"Numerically stable implementation of the operation\n",
    "    value.exp().sum(dim, keepdim).log()\n",
    "    \"\"\"\n",
    "    # TODO: torch.max(value, dim=None) threw an error at time of writing\n",
    "    if dim is not None:\n",
    "        m, _ = torch.max(value, dim=dim, keepdim=True)\n",
    "        value0 = value - m\n",
    "        if keepdim is False:\n",
    "            m = m.squeeze(dim)\n",
    "        return m + torch.log(torch.sum(torch.exp(value0),\n",
    "                                       dim=dim, keepdim=keepdim))\n",
    "    else:\n",
    "        m = torch.max(value)\n",
    "        sum_exp = torch.sum(torch.exp(value - m))\n",
    "        return m + torch.log(sum_exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "54d3a3c0-c7e1-4c21-b5bf-3f3955d675e1"
    }
   },
   "outputs": [],
   "source": [
    "#################\n",
    "## Model class ##\n",
    "#################\n",
    "\n",
    "class ARHMM(nn.Module):\n",
    "    def __init__(self, n_discrete_states, latent_dim_size_h, transition_init, kappa, alpha, batch_size, nlags):\n",
    "        super(ARHMM, self).__init__()\n",
    "        self.n_discrete_states = n_discrete_states\n",
    "        self.latent_dim_size_h = latent_dim_size_h\n",
    "        self.transition_init=transition_init\n",
    "        self.batch_size=batch_size\n",
    "        self.nlags = nlags\n",
    "        self.kappa = kappa\n",
    "        self.alpha = alpha\n",
    "        self.__build_model()\n",
    "    \n",
    "    def __build_model(self):\n",
    "\n",
    "        # Emission parameters\n",
    "        self.As = nn.Parameter(torch.zeros((self.n_discrete_states, self.latent_dim_size_h*self.nlags, self.latent_dim_size_h)))\n",
    "        self.bs = nn.Parameter(torch.zeros((self.n_discrete_states, self.latent_dim_size_h)))\n",
    "        self.inv_softplus_Qs = nn.Parameter(torch.ones((self.n_discrete_states, self.latent_dim_size_h)))\n",
    "\n",
    "        # Transition bias network (x -> transition bias + transition prob)\n",
    "        self.log_transition_proba = \\\n",
    "                nn.Parameter(torch.log(\n",
    "                self.transition_init * torch.eye(self.n_discrete_states) + (1-self.transition_init) / self.n_discrete_states * torch.ones((self.n_discrete_states, self.n_discrete_states))))\n",
    "\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def get_tiled_normalized_log_Ps(self):\n",
    "        \n",
    "        normalized_Ps = self.log_transition_proba - log_sum_exp(self.log_transition_proba, dim=-1, keepdim=True)\n",
    "        \n",
    "        return normalized_Ps.unsqueeze(0).repeat(self.batch_size-1,1,1)\n",
    "    \n",
    "    def get_transition_dirichlet_prior(self):\n",
    "        \n",
    "        log_Ps = self.log_transition_proba-log_sum_exp(self.log_transition_proba,dim=-1,keepdim=True)\n",
    "        \n",
    "        lp = 0\n",
    "        for i_state in range(self.n_discrete_states):\n",
    "            concentration = self.alpha*torch.ones(self.n_discrete_states) / self.n_discrete_states\n",
    "            concentration[i_state] += self.kappa\n",
    "            lp += ((log_Ps[i_state] * (concentration - 1.0)).sum(-1) +\n",
    "                torch.lgamma(concentration.sum(-1)) -\n",
    "                torch.lgamma(concentration).sum(-1))\n",
    "           # dirichlet_dist = torch.distributions.dirichlet.Dirichlet(concentration)\n",
    "           # lp += torch.sum(dirichlet_dist.log_prob(Ps[i_state]))\n",
    "        return lp\n",
    "\n",
    "    def get_lls(self,h):\n",
    "        E_hs = torch.transpose(torch.matmul(torch.cat(([h[self.nlags-1-i:self.batch_size-1-i] for i in range(self.nlags,-1,-1)]),dim=1), self.As),1,0) + self.bs       # T-1 x K x H\n",
    "        E_hs = torch.cat((self.bs.view(1, self.n_discrete_states, self.latent_dim_size_h).repeat(nlags,1,1) , E_hs), 0)                             # T x K x H\n",
    "        \n",
    "        lls = -0.5 * torch.sum((h.unsqueeze(1) - E_hs)**2 / self.softplus(self.inv_softplus_Qs), dim=2)         # T x K\n",
    "        lls += -0.5 * torch.sum(math.log(2 * math.pi) + torch.log(self.softplus(self.inv_softplus_Qs)), dim=1)  # K \n",
    "\n",
    "        # Below uses torch multivariate but is slower \n",
    "#         lls = torch.zeros(self.batch_size,self.n_discrete_states)\n",
    "#         for i_k in range(self.n_discrete_states):\n",
    "#             normal_dist = torch.distributions.multivariate_normal.MultivariateNormal(E_hs[:,i_k],covariance_matrix=torch.diag(self.softplus(self.inv_softplus_Qs)[i_k]))\n",
    "#             lls[:,i_k] = normal_dist.log_prob(h)\n",
    "        return lls\n",
    "    \n",
    "    def get_log_pi0(self):\n",
    "        return -math.log(self.n_discrete_states) * torch.ones(self.n_discrete_states)\n",
    "    \n",
    "    def forward(self, h):\n",
    "        return self.get_log_pi0(), self.get_lls(h), self.get_tiled_normalized_log_Ps()\n",
    "    \n",
    "    def sample_states(self, h, log_pi0, lls, log_Ps,num_samples=1):\n",
    "\n",
    "        return torch.stack([hmm_sample(log_pi0, log_Ps, lls) for _ in range(num_samples)])\n",
    "    \n",
    "    def EM_loss(self, zs, h, log_pi0, lls, log_Ps):\n",
    "        \n",
    "        dirichlet_prior = self.get_transition_dirichlet_prior()\n",
    "    \n",
    "        n_samples = zs.shape[0]\n",
    "        lp = 0\n",
    "        for i_sample in range(n_samples):\n",
    "\n",
    "            # Compute log p(z | theta)\n",
    "            lp += torch.sum(log_Ps[torch.arange(0, self.batch_size-1).long(), zs[i_sample,:-1], zs[i_sample,1:]])\n",
    "             \n",
    "            # Compute log p(x | z, theta)\n",
    "            lp += torch.sum(lls[torch.arange(0, self.batch_size).long(), zs])\n",
    "           \n",
    "        tt = copy.deepcopy(lp.detach().numpy())\n",
    "        \n",
    "        # TO DO: change 901 to parameter!!!\n",
    "        lp += torch.sum(dirichlet_prior)*(1/901)\n",
    "\n",
    "        return -lp/(h.shape[0]*h.shape[1])\n",
    "\n",
    "    def SGD_loss(self, h, log_pi0, lls, log_Ps):\n",
    "        \n",
    "        dirichlet_prior = self.get_transition_dirichlet_prior()\n",
    "    \n",
    "        log_prob = hmm_marginal_likelihood(log_pi0, log_Ps, lls) + dirichlet_prior*(1/901)\n",
    "        \n",
    "        return -log_prob/(h.shape[0]*h.shape[1])\n",
    "        \n",
    "    def get_expected_states(self, h):\n",
    "\n",
    "        log_Ps = self.get_tiled_normalized_log_Ps()\n",
    "        log_PsT = log_Ps.transpose(1, 2) \n",
    "        \n",
    "        lls = self.get_lls(h)\n",
    "        \n",
    "        # Forwards pass\n",
    "        alpha = torch.zeros_like(lls)\n",
    "        alpha[0] = -math.log(self.n_discrete_states) + lls[0] \n",
    "        for t in range(alpha.shape[0]-1):\n",
    "            alpha[t+1] = log_sum_exp(alpha[t] + log_PsT[t],dim=1) + lls[t+1]\n",
    "\n",
    "        # Backwards pass\n",
    "        beta = torch.zeros_like(lls)\n",
    "        for t in range(beta.shape[0]-2,-1,-1):\n",
    "            beta[t] = log_sum_exp(log_Ps[t]+beta[t+1]+lls[t+1],dim=1)\n",
    "\n",
    "        # Combine to get posterior over z\n",
    "        expected_z = alpha+beta\n",
    "        expected_z -= expected_z.max(1)[0].view((-1,1))\n",
    "        expected_z = torch.exp(expected_z)\n",
    "        expected_z /= expected_z.sum(1).view((-1,1))\n",
    "\n",
    "        return expected_z\n",
    "    \n",
    "    def initialize_transitions(self, data_gen, nb_tng_batches, device, L2_reg=0.01):\n",
    "\n",
    "        # Split the data into n_discrete_state chunks, fit linear regression to each chunk separately\n",
    "        data_split = np.floor(nb_tng_batches/self.n_discrete_states)\n",
    "        \n",
    "        i_discrete_state = 0\n",
    "        start_collecting=1\n",
    "\n",
    "        for batch_nb in range(nb_tng_batches):\n",
    "            \n",
    "            # Get this batch of data\n",
    "            pca, i_mouse, i_batch = next(data_gen)\n",
    "            pca = torch.tensor(pca).to(device).float()\n",
    "            X = torch.cat(([pca[nlags-1-i:pca.shape[0]-1-i] for i in range(nlags,-1,-1)]),dim=1) \n",
    "            X = F.pad(X,(1,0),value=1)\n",
    "            Y = pca[self.nlags:]\n",
    "\n",
    "            # Collect X/Y/XTX/XTY \n",
    "            if start_collecting: # start of a new chunk\n",
    "                all_X = X\n",
    "                all_Y = Y\n",
    "                XTX = torch.matmul(X.transpose(1,0),X)\n",
    "                XTY = torch.matmul(X.transpose(1,0),Y)\n",
    "                start_collecting=0\n",
    "            else:\n",
    "                all_X = torch.cat((all_X,X),0)\n",
    "                all_Y = torch.cat((all_Y,Y),0)\n",
    "                XTX += torch.matmul(X.transpose(1,0),X)\n",
    "                XTY += torch.matmul(X.transpose(1,0),Y)\n",
    "\n",
    "            if i_discrete_state < self.n_discrete_states:\n",
    "                if np.mod(batch_nb+1,data_split)==0:\n",
    "                    \n",
    "                    # Calculate weights for this chunk\n",
    "                    reg_XTX = XTX+L2_reg*torch.eye(X.shape[1])\n",
    "                    XTX_inv = torch.inverse(reg_XTX)\n",
    "                    W = torch.matmul(XTX_inv,XTY)\n",
    "\n",
    "                    self.As.data[i_discrete_state] = W[1:,:].data\n",
    "                    self.bs.data[i_discrete_state] = W[0,:].data\n",
    "\n",
    "                    # Reconstruct to get residuals/covariances \n",
    "                    Y_hat = torch.matmul(all_X,W)\n",
    "                    residuals = Y_hat-all_Y\n",
    "                    Qs = torch.var(residuals,0).data\n",
    "                    self.inv_softplus_Qs.data[i_discrete_state] = torch.log(torch.exp(Qs)-1)\n",
    "                    \n",
    "                    # Reset\n",
    "                    start_collecting=1\n",
    "                    i_discrete_state +=1\n",
    "\n",
    "        if i_discrete_state < self.n_discrete_states-1:\n",
    "            print('ERROR WITH INITIALIZATION')\n",
    "            sys.exit(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "9a4ba0cf-0382-4a27-9f57-a3958d38e5f1"
    }
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "## Create/initialize model ##\n",
    "#############################\n",
    "\n",
    "transition_init=0.5\n",
    "n_discrete_states=100\n",
    "latent_dim_size_h=10\n",
    "nlags=3\n",
    "alpha=200\n",
    "kappa=1e6\n",
    "\n",
    "model = ARHMM(n_discrete_states, latent_dim_size_h, transition_init, kappa, alpha, batch_size, nlags)\n",
    "\n",
    "# Initialize model\n",
    "model.initialize_transitions(data_gen, nb_tng_batches, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ##########################\n",
    "# ## Load in Gibb's Model ##\n",
    "# ##########################\n",
    "\n",
    "# model_fit = 'clean_data_pca_gibbs_sampling_100_iter.p'\n",
    "# model_fit = joblib.load(model_fit)\n",
    "\n",
    "\n",
    "# model.As.data = torch.tensor(np.swapaxes(np.asarray(model_fit['model_parameters'][0]['ar_mat'])[:,:,:-1],2,1)).float()\n",
    "# model.bs.data = torch.tensor(np.asarray(model_fit['model_parameters'][0]['ar_mat'])[:,:,-1]).float()\n",
    "# sig = np.asarray(model_fit['model_parameters'][0]['sig'])\n",
    "# diag_sig = np.asarray([np.diag(sig[i]) for i in range(100)])\n",
    "# Qs = torch.tensor(sig).float()\n",
    "# model.inv_softplus_Qs.data = torch.tensor(np.log(np.exp(diag_sig)-1)).float()\n",
    "# model.log_transition_proba.data = torch.tensor(np.log(np.asarray(model_fit['model_parameters'][0]['transition_matrix']))).float()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "c441ff87-3ff0-478d-8ae1-0036e0b05805"
    }
   },
   "outputs": [],
   "source": [
    "# # # #######################\n",
    "# # # ## SGD loss training ##\n",
    "# # # #######################\n",
    "\n",
    "# optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=.01)\n",
    "# for i_epoch in range(100):\n",
    "#     train_loss = 0\n",
    "#     for i_train in tqdm(range(nb_tng_batches)):\n",
    "#         pca, i_mouse, i_batch = next(data_gen)\n",
    "#         pca = torch.tensor(pca).to(device).float()\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         log_pi0, lls, log_Ps = model(pca)\n",
    "#         loss = model.SGD_loss(pca,log_pi0, lls, log_Ps)\n",
    "        \n",
    "#         if i_epoch > 0:\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#         train_loss += loss.item()\n",
    "#     print(\"Epoch: \", i_epoch, \" \", train_loss/nb_tng_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbpresent": {
     "id": "83457dce-3e24-477c-8dc1-42b4e5210177"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 272/901 [01:03<02:27,  4.28it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3be6dc0e7faf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mlog_pi0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_Ps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mzs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_pi0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_Ps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0munique_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munique_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-70aa956fc6e1>\u001b[0m in \u001b[0;36msample_states\u001b[0;34m(self, h, log_pi0, lls, log_Ps, num_samples)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_pi0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_Ps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhmm_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_pi0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_Ps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mEM_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_pi0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_Ps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-70aa956fc6e1>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_pi0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_Ps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhmm_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_pi0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_Ps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mEM_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_pi0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_Ps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/DattaAnalysis/datta/datta/messages/torchhmm.py\u001b[0m in \u001b[0;36mhmm_sample\u001b[0;34m(log_pi0, log_Ps, ll)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# observations up to and including those from time t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mhmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_pi0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_Ps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# Sample backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "######################\n",
    "## EM loss training ##\n",
    "######################\n",
    "all_training_loss = []\n",
    "all_likelihood_loss = []\n",
    "all_dirichlet_loss = []\n",
    "n_unique_states = []\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=.001)\n",
    "\n",
    "for i_epoch in range(1):\n",
    "    train_loss = 0\n",
    "    dirichlet_loss=0\n",
    "    likelihood_loss = 0\n",
    "    unique_states=np.empty((0,))\n",
    "    for i_train in tqdm(range(nb_tng_batches)):\n",
    "        \n",
    "        pca, i_mouse, i_batch = next(data_gen)\n",
    "        pca = torch.tensor(pca).to(device).float()\n",
    "        \n",
    "        log_pi0, lls, log_Ps = model(pca)\n",
    "\n",
    "        zs = model.sample_states(pca, log_pi0, lls, log_Ps)\n",
    "\n",
    "        unique_states = np.unique(np.concatenate((zs.detach().numpy().reshape((-1,)),unique_states)))\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = model.EM_loss(zs, pca, log_pi0, lls, log_Ps)\n",
    "        d_loss = -1*((model.get_transition_dirichlet_prior())/(pca.shape[0]*pca.shape[1])).detach().numpy()/901\n",
    "        dirichlet_loss += d_loss\n",
    "        likelihood_loss += ((loss-d_loss)).detach().numpy()\n",
    "        \n",
    "        if np.isnan(loss.item()):\n",
    "            break\n",
    "        if i_epoch > 0:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    if np.isnan(loss.item()):\n",
    "        break\n",
    "    print(\"Epoch: \", i_epoch, \" \", train_loss/nb_tng_batches)\n",
    "    all_training_loss.append(train_loss/nb_tng_batches)\n",
    "    all_likelihood_loss.append(likelihood_loss/nb_tng_batches)\n",
    "    all_dirichlet_loss.append(dirichlet_loss/nb_tng_batches)\n",
    "    n_unique_states.append(unique_states.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "## Analyze model ##\n",
    "###################\n",
    "\n",
    "# Save model\n",
    "# torch.save(model, 'model.pt')\n",
    "\n",
    "train_loss=0\n",
    "dirichlet_loss=0\n",
    "these_counts = np.zeros((100,))\n",
    "b_freqs = np.empty((0,))\n",
    "for i_train in tqdm(range(nb_tng_batches)):\n",
    "    pca, i_mouse, i_batch = next(data_gen)\n",
    "    pca = torch.tensor(pca).to(device).float()\n",
    "    \n",
    "    log_pi0, lls, log_Ps = model(pca)\n",
    "    zs = model.sample_states(pca, log_pi0, lls, log_Ps)\n",
    "    loss = model.EM_loss(zs, pca, log_pi0, lls, log_Ps)\n",
    "    dirichlet_loss += model.get_transition_dirichlet_prior()\n",
    "    train_loss += loss.item()-dirichlet_loss\n",
    "    \n",
    "    \n",
    "    expected_z = model.get_expected_states(pca)\n",
    "    these_counts += np.histogram(np.argmax(expected_z.detach().numpy(),1),np.arange(-.5,100.5))[0]\n",
    "    these_lengths = np.diff(np.where(np.ediff1d(np.argmax(expected_z.detach().numpy(),1))!=0))\n",
    "    b_freqs = np.concatenate((b_freqs,these_lengths.reshape((-1,))))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 14})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4,1,figsize=(10,20),sharex=True)\n",
    "ax[0].plot(np.asarray(all_training_loss),'k')\n",
    "ax[1].plot(np.asarray(all_likelihood_loss),'k')\n",
    "ax[2].plot(np.asarray(all_dirichlet_loss),'k')\n",
    "ax[3].plot(np.asarray(n_unique_states),'k')\n",
    "\n",
    "ax[3].set_xlabel('Epoch Number')\n",
    "ax[0].set_ylabel('Training Loss')\n",
    "ax[1].set_ylabel('Likelihood Loss')\n",
    "ax[2].set_ylabel('Dirichlet Loss')\n",
    "ax[3].set_ylabel('# unique states')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(20,15\n",
    "                                   ))\n",
    "ax.imshow(expected_z.detach().numpy().T,cmap='gray_r',vmin=0,vmax=1)\n",
    "ax.set_xlabel('Time (frames)')\n",
    "ax.set_ylabel('State Number')\n",
    "ax.set_title('Expected z state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.argmax(expected_z.detach().numpy(),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zs = model.sample_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(0,400,50)\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,5))\n",
    "ax.hist(b_freqs,bins,color='k')\n",
    "ax.set_xlabel('Length of states')\n",
    "ax.set_ylabel('Occurrences')\n",
    "ax.set_xlim([-10,410])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(10,5))\n",
    "ax.hist(np.arange(0,100),np.arange(0,100),weights=these_counts,color='k');\n",
    "ax.set_xlabel('Expected State')\n",
    "ax.set_ylabel('Occurrences')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_states_over_1 = np.sum(these_counts/np.sum(these_counts)*100>1)\n",
    "n_states_over_2 = np.sum(these_counts/np.sum(these_counts)*100>2)\n",
    "mean_freq = np.mean(b_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_states_over_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_states_over_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
