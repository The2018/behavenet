{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "import pickle\n",
    "from ssm.stats import multivariate_normal_logpdf\n",
    "from ssm.primitives import hmm_expected_states, hmm_sample\n",
    "from pylds.lds_messages_interface import info_E_step\n",
    "# from behavenet.fitting.utils import build_data_generator, create_tt_experiment\n",
    "# from behavenet.fitting.utils import add_lab_defaults_to_parser, get_output_session_dir, get_expt_dir\n",
    "# from test_tube import HyperOptArgumentParser\n",
    "# from behavenet.fitting.decoding_grid_search import get_decoding_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_params(strategy, args):\n",
    "\n",
    "#     parser = HyperOptArgumentParser(strategy)\n",
    "\n",
    "#     # most important arguments\n",
    "#     parser.add_argument('--search_type', type=str)  # grid_search, test\n",
    "#     parser.add_argument('--lab_example', type=str)  # musall, steinmetz, datta\n",
    "#     parser.add_argument('--tt_save_path', type=str)\n",
    "#     parser.add_argument('--data_dir', type=str)\n",
    "#     parser.add_argument('--model_type', default='ff', choices=['ff', 'ff-mv', 'linear', 'linear-mv', 'lstm'], type=str)\n",
    "#     parser.add_argument('--model_class', default='neural-ae', choices=['neural-ae', 'neural-arhmm', 'ae-neural', 'arhmm-neural'], type=str)\n",
    "#     parser.add_argument('--sessions_csv', default='', type=str, help='specify multiple sessions')\n",
    "\n",
    "#     # arguments for computing resources (infer n_gpu_workers from visible gpus)\n",
    "#     parser.add_argument('--tt_n_gpu_trials', default=1000, type=int)\n",
    "#     parser.add_argument('--tt_n_cpu_trials', default=100000, type=int)\n",
    "#     parser.add_argument('--tt_n_cpu_workers', default=5, type=int)\n",
    "#     parser.add_argument('--mem_limit_gb', default=8.0, type=float)\n",
    "#     parser.add_argument('--gpus_viz', default='0;1', type=str)\n",
    "\n",
    "#     # add data generator arguments\n",
    "#     parser.add_argument('--reg_list', default='none', type=str, choices=['none', 'arg', 'all'])\n",
    "#     parser.add_argument('--subsample_regions', default='none', choices=['none', 'single', 'loo'])\n",
    "#     parser.add_argument('--device', default='cuda', type=str)\n",
    "#     parser.add_argument('--as_numpy', action='store_true', default=False)\n",
    "#     parser.add_argument('--batch_load', action='store_true', default=False)\n",
    "#     parser.add_argument('--rng_seed', default=0, type=int)\n",
    "\n",
    "#     # add fitting arguments\n",
    "#     parser.add_argument('--val_check_interval', default=1)\n",
    "\n",
    "#     # get lab-specific arguments\n",
    "#     namespace, extra = parser.parse_known_args(args)\n",
    "#     add_lab_defaults_to_parser(parser, namespace.lab_example)\n",
    "#     namespace, extra = parser.parse_known_args(args)  # ugly\n",
    "\n",
    "#     # add regions to opt_list if desired\n",
    "#     if namespace.reg_list == 'all':\n",
    "#         parser.opt_list('--region', options=get_region_list(namespace), type=str, tunable=True)\n",
    "#     elif namespace.reg_list == 'arg':\n",
    "#         parser.add_argument('--region', default='all', type=str)\n",
    "#     elif namespace.reg_list == 'none':  # TODO: fix this ambiguity\n",
    "#         parser.add_argument('--region', default='all', type=str)\n",
    "#     else:\n",
    "#         raise ValueError(\n",
    "#             '\"%s\" is not a valid region_list' % namespace.region_list)\n",
    "\n",
    "#     get_decoding_params(namespace, parser)\n",
    "\n",
    "#     return parser.parse_args(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# command_line_arg = '--search_type test --lab_example musall --animal mSM36 --session 05-Dec-2017 --tt_save_path /media/gssda/behavenet/results/ --data_dir /media/gssda/behavenet/data/  --model_type ff --model_class neural-ae --experiment_name grid_search --export_predictions --ae_experiment_name ae-dim-test --ae_model_type conv --n_ae_latents 8 --min_n_epochs 10 --max_n_epochs 500 --device cpu --n_lags 4 --l2_reg 1e-4 --n_hid_layers 3 --ae_multisession 0'\n",
    "# hparams = get_params('grid_search', command_line_arg.split(' '))\n",
    "# hparams = vars(hparams)\n",
    "# hparams.pop('trials', False)\n",
    "# hparams.pop('generate_trials', False)\n",
    "# hparams.pop('optimize_parallel', False)\n",
    "# hparams.pop('optimize_parallel_cpu', False)\n",
    "# hparams.pop('optimize_parallel_gpu', False)\n",
    "# hparams.pop('optimize_trials_parallel_gpu', False)\n",
    "\n",
    "# # create test-tube experiment\n",
    "# #hparams, sess_ids, exp = create_tt_experiment(hparams)\n",
    "# hparams['session_dir'], sess_ids = get_output_session_dir(hparams)\n",
    "# hparams['expt_dir'] = 'temp/'\n",
    "# hparams['version'] = 0\n",
    "# # build data generator\n",
    "# ae_data_generator = build_data_generator(hparams, sess_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# command_line_arg = '--search_type test --lab_example musall --animal mSM36 --session 05-Dec-2017 --tt_save_path /media/gssda/behavenet/results/ --data_dir /media/gssda/behavenet/data/ --model_type ff --model_class neural-arhmm --experiment_name grid_search --n_ae_latents 8 --arhmm_experiment_name grid_search --n_arhmm_states 8 --kappa 0 --noise_type gaussian --min_n_epochs 10 --max_n_epochs 500 --n_lags 4 --l2_reg 1e-4 --n_hid_layers 1 --arhmm_multisession 0 --device cpu'\n",
    "# hparams = get_params('grid_search', command_line_arg.split(' '))\n",
    "# hparams = vars(hparams)\n",
    "# hparams.pop('trials', False)\n",
    "# hparams.pop('generate_trials', False)\n",
    "# hparams.pop('optimize_parallel', False)\n",
    "# hparams.pop('optimize_parallel_cpu', False)\n",
    "# hparams.pop('optimize_parallel_gpu', False)\n",
    "# hparams.pop('optimize_trials_parallel_gpu', False)\n",
    "\n",
    "# # create test-tube experiment\n",
    "# #hparams, sess_ids, exp = create_tt_experiment(hparams)\n",
    "# hparams['session_dir'], sess_ids = get_output_session_dir(hparams)\n",
    "# hparams['expt_dir'] = 'temp/'\n",
    "# hparams['version'] = 0\n",
    "# # build data generator\n",
    "# arhmm_data_generator = build_data_generator(hparams, sess_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 545\n",
    "# K = 8\n",
    "\n",
    "# ae_neural = [None for i in range(N)]\n",
    "# ae_latents = [None for i in range(N)]\n",
    "# arhmm_neural = [None for i in range(N)]\n",
    "# arhmm_states = [None for i in range(N)]\n",
    "\n",
    "# for ii in range(ae_data_generator.n_tot_batches['train']):\n",
    "#     ae_data, _ = ae_data_generator.next_batch('train')\n",
    "#     arhmm_data, _ = arhmm_data_generator.next_batch('train')\n",
    "    \n",
    "#     ae_neural[ae_data['batch_indx'].item()] = ae_data['neural'].cpu().detach().numpy().squeeze()\n",
    "#     ae_latents[ae_data['batch_indx'].item()] = ae_data['ae_latents'].cpu().detach().numpy().squeeze()\n",
    "    \n",
    "#     arhmm_neural[arhmm_data['batch_indx'].item()] = arhmm_data['neural'].cpu().detach().numpy().squeeze()\n",
    "#     arhmm_states[arhmm_data['batch_indx'].item()] = arhmm_data['arhmm_states'].cpu().detach().numpy().squeeze()\n",
    "    \n",
    "# neural = [v for v in ae_neural if v is not None]\n",
    "# xs = [v for v in ae_latents if v is not None]\n",
    "# zs = [v for v in arhmm_states if v is not None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savez('arhmm_decoding_data.npz',neural=neural, latents=xs, states=zs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('arhmm_decoding_data.npz')\n",
    "neural = data['neural']\n",
    "xs = data['latents']\n",
    "zs = data['states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have to lag the neural activity for each batch\n",
    "\n",
    "W = 8\n",
    "N = neural[0].shape[1]\n",
    "\n",
    "ns_window = [_ for i in range(len(neural))]\n",
    "for i in range(len(neural)):\n",
    "    T = neural[i].shape[0]\n",
    "    neural_pad = np.concatenate([np.zeros((W//2, N)), neural[i], np.zeros((W//2, N))])\n",
    "    ns_window[i] = np.column_stack([neural_pad[w:T+w] for w in range(W)] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatente into sequences, take only part for now\n",
    "T=10000\n",
    "ns_window_flat =np.concatenate(ns_window,axis=0)[:T]\n",
    "zs_flat = np.concatenate(zs,axis=0)[:T]\n",
    "xs_flat = np.concatenate(xs,axis=0)[:T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erb2180/miniconda3/envs/behavenet/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "\n",
    "recog_z = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "recog_z.fit(ns_window_flat, zs_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "\n",
    "recog_x = LinearRegression()\n",
    "recog_x.fit(ns_window_flat, xs_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in ARHMM model and get parameters\n",
    "D=8\n",
    "arhmm_model = pickle.load(open('best_val_model.pt','rb'))\n",
    "\n",
    "P = arhmm_model.transitions.transition_matrix\n",
    "As = arhmm_model.observations.As\n",
    "bs = arhmm_model.observations.bs\n",
    "Qs = arhmm_model.observations.Sigmas\n",
    "\n",
    "evals, evecs = np.linalg.eig(P.T)\n",
    "perm = np.argsort(evals)[::-1]\n",
    "evals, evecs = evals[perm], evecs[:, perm]\n",
    "assert np.allclose(evals[0], 1.0)\n",
    "if np.any(evecs[:,0] <= 0):\n",
    "    evecs[:,0] = -1*evecs[:,0]\n",
    "assert np.all(evecs[:,0] >= 0) \n",
    "pz_infty = np.real(evecs[:, 0] / evecs[:, 0].sum())\n",
    "\n",
    "mu_infty = np.zeros((K, D))\n",
    "Sigma_infty = np.zeros((K, D, D))\n",
    "for k in range(K):\n",
    "    mu_infty[k] = np.mean(xs_flat[zs_flat == k],axis=0)\n",
    "    #Sigma_infty[k] = np.cov(training_ae[training_arhmm == k].T)\n",
    "    Sigma_infty[k] = np.cov(xs_flat.T)\n",
    "    \n",
    "mu0 = np.zeros(D)\n",
    "Sigma0 = np.eye(D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the information form.  It will generalize better to VI.\n",
    "from pylds.lds_messages_interface import info_E_step\n",
    "\n",
    "# Compute the info potentials for the initial condition\n",
    "def _info_params(mu0, Sigma0, As, bs, Qs, q_mu_x, q_Sigma_x, Sigma_infty, mu_infty, Ez, z_sample):\n",
    "    # parameter checking\n",
    "    T, K = Ez.shape\n",
    "    assert As.shape[0] == K and As.ndim == 3 and As.shape[1] == As.shape[2]\n",
    "    D = As.shape[1]\n",
    "    assert mu0.shape == (D,)\n",
    "    assert Sigma0.shape == (D, D)\n",
    "    assert bs.shape == (K, D)\n",
    "    assert Qs.shape == (K, D, D)\n",
    "    assert q_mu_x.shape == (T, D)\n",
    "    assert q_Sigma_x.shape == (D, D)\n",
    "    \n",
    "    # Make pseudo-inputs (all ones) for bias terms\n",
    "    inputs = np.ones((T, 1))\n",
    "    \n",
    "    # Convert initial distribution to info form\n",
    "    # (ignore normalizing constants)\n",
    "    J0 = np.linalg.inv(Sigma0)\n",
    "    h0 = J0 @ mu0\n",
    "    log_Z0 = 0\n",
    "\n",
    "    # Info dynamics parameters\n",
    "    J_pair_22 = np.linalg.inv(Qs)\n",
    "    J_pair_21 = -np.matmul(np.linalg.inv(Qs), As)\n",
    "    J_pair_11 = np.matmul(np.swapaxes(As, 1, 2), -J_pair_21)\n",
    "    mBTQiA = np.matmul(np.swapaxes(bs[:, :, None], 1, 2), J_pair_21)\n",
    "    BTQi = np.matmul(np.swapaxes(bs[:, :, None], 1, 2), J_pair_22)\n",
    "\n",
    "    # Get expected sufficient statistics by integrating over z\n",
    "    J_pair_22 = np.einsum('tk, kij -> tij', Ez[:-1], J_pair_22)\n",
    "    J_pair_21 = np.einsum('tk, kij -> tij', Ez[:-1], J_pair_21)\n",
    "    J_pair_11 = np.einsum('tk, kij -> tij', Ez[:-1], J_pair_11)\n",
    "    mBTQiA = np.einsum('tk, kij -> tij', Ez[:-1], mBTQiA)\n",
    "    BTQi = np.einsum('tk, kij -> tij', Ez[:-1], BTQi)\n",
    "    h_pair_1 = np.einsum('tu, tud -> td', inputs[:-1], mBTQiA)\n",
    "    h_pair_2 = np.einsum('tu, tud -> td', inputs[:-1], BTQi)\n",
    "    log_Z_pair = np.zeros(T-1)\n",
    "\n",
    "    # Info emission parameters\n",
    "    J_obs = (np.linalg.inv(q_Sigma_x) - np.linalg.inv(Sigma_infty))[z_sample] #+100*np.eye(8*3)\n",
    "    h_recog = np.dot(np.linalg.inv(q_Sigma_x), q_mu_x.T).T #np.linalg.solve(q_Sigma_x+10000*np.eye(8*3), q_mu_x.T).T\n",
    "    h_infty = np.linalg.solve(Sigma_infty, mu_infty)[z_sample]\n",
    "    h_obs = h_recog + h_infty\n",
    "    log_Z_obs = np.zeros(T)\n",
    "    \n",
    "    return J0, h0, log_Z0, \\\n",
    "           J_pair_11, J_pair_21, J_pair_22, h_pair_1, h_pair_2, log_Z_pair, \\\n",
    "           J_obs, h_obs, log_Z_obs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_iter = 100\n",
    "t=5 # which batch to use\n",
    "\n",
    "\n",
    "# Initialize q(z) with just the learned recognition potential\n",
    "log_qz = recog_z.predict_log_proba(ns_window[t])\n",
    "q_mu_x = recog_x.predict(ns_window[t])\n",
    "q_Sigma_x = np.cov((xs[t] - q_mu_x).T)\n",
    "\n",
    "z_potential = log_qz - np.log(pz_infty)\n",
    "Ez, _, _ = hmm_expected_states(np.log(pz_infty), np.log(P)[None, :, :], z_potential)\n",
    "z_sample = hmm_sample(np.log(pz_infty), np.log(P)[None, :, :], z_potential)\n",
    "\n",
    "for i in range(n_iter):\n",
    "    # compute the expected value of x given z and the observation potential\n",
    "    _, Ex, _, _ = info_E_step(\n",
    "        *_info_params(mu0, Sigma0, As, bs, Qs, \n",
    "                      q_mu_x, q_Sigma_x, Sigma_infty, mu_infty, Ez, z_sample)\n",
    "    )\n",
    "\n",
    "    # Update z, now including the dynamics potential\n",
    "    # TODO: Should really include the covariance of x in this update too\n",
    "    z_dyn_potential = np.column_stack(\n",
    "        [multivariate_normal_logpdf(Ex[1:], Ex[:-1] @ A.T + b, Q) \n",
    "         for A, b, Q in zip(As, bs, Qs)])\n",
    "    z_dyn_potential = np.row_stack((np.zeros(K), z_dyn_potential))\n",
    "    z_potential = log_qz - np.log(pz_infty) + z_dyn_potential\n",
    "    Ez, _, _ = hmm_expected_states(np.log(pz_infty), np.log(P)[None, :, :], z_potential)\n",
    "    #print(np.unique(Ez))\n",
    "    print(\"MSE: \", np.mean((Ex[:,:D] - xs[t])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_observations = np.zeros((len(zs[t]),D))\n",
    "for i_t in range(len(zs[t])):\n",
    "    sampled_observations[i_t] = arhmm_model.observations.sample_x(np.argmax(log_qz,axis=1)[i_t],sampled_observations[:i_t], input=[0], with_noise=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xs[t][:,0],'k')\n",
    "plt.plot(q_mu_x[:,0],'b')\n",
    "plt.plot(Ex[:,0],'r')\n",
    "plt.plot(sampled_observations[:,0],'g')\n",
    "plt.legend(['Real Latents', 'Decoded latents', 'After one info_E_step', 'Conditionally sampled latents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(zs[t],'k')\n",
    "plt.plot(np.argmax(log_qz,axis=1),'b')\n",
    "plt.plot(np.argmax(Ez,axis=1),'r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "behavenet",
   "language": "python",
   "name": "behavenet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
