{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and analyze autoencoders\n",
    "The first step of the BehaveNet pipeline is to compress the behavioral videos with a convolutional autoencoder (CAE), yielding a low-dimensional continuous representation of behavior that is useful for downstream analyses.\n",
    "\n",
    "Because the CAEs currently require significant computation time (generally >12 hours on a GPU) the data downloaded in the previous notebook also contains already trained CAEs, which we will analyze here.\n",
    "\n",
    "There are a variety of files that are automatically saved during the fitting of a CAE, which can be used for later analyses such as those below. Some of these files (many of which are common to all BehaveNet models, not just the CAE):\n",
    "* `best_val_model.pt`: the best CAE (not necessarily from the final training epoch) as determined by computing the loss on validation data\n",
    "* `meta_tags.csv`: hyperparameters associated with data, computational resources, and model\n",
    "* `metrics.csv`: metrics computed on dataset as a function of epochs; the default is that metrics are computed on training and validation data every epoch (and reported as a mean over all batches) while metrics are computed on test data only at the end of training using the best model (and reported per batch).\n",
    "* `[lab_id]_[expt_id]_[animal_id]_[session_id]_latents.pkl`: list of np.ndarrays of CAE latents computed using the best model\n",
    "* `session_info.csv`: sessions used to fit the model\n",
    "\n",
    "To fit your own CAEs, see additional documentation [here](https://behavenet.readthedocs.io/en/latest/source/user_guide.autoencoders.html). The downloaded CAEs used the default architecture with 9 latents, a learning rate of 1e-4, and no regularization. Models fit to individual datasets were trained for 600 epochs, while the model fit to both datasets was trained for 300 epochs.\n",
    "\n",
    "**Note**: The BehaveNet models are trained on batches of data, which here are defined as one trial per batch; at 189 frames per trial, 2 camera views, and 128x128 images, a batch of data is of size (189, 2, 128, 128). For datasets that do not have a trial structure (i.e. spontaneous behavior) we recommend splitting frames into arbitrarily defined \"trials\", the length of which should depend on the autocorrelation of the behavior (i.e. trials should not be shorter than the temporal extent of relevant behaviors). For the NP dataset in the original paper we used batch sizes of 1000 frames (~25 sec).\n",
    "\n",
    "<br>\n",
    "\n",
    "### Contents\n",
    "* [Plot train and val losses as a function of epochs](#Plot-train-and-val-losses-as-a-function-of-epochs)\n",
    "* [Plot train/val losses as a function of dataset](#Plot-train/val-losses-as-a-function-of-dataset)\n",
    "* [Make reconstruction movies](#Make-reconstruction-movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from behavenet import get_user_dir, make_dir_if_not_exists\n",
    "from behavenet.fitting.utils import get_expt_dir\n",
    "from behavenet.fitting.utils import get_session_dir\n",
    "from behavenet.fitting.utils import get_best_model_version\n",
    "from behavenet.fitting.utils import get_lab_example\n",
    "\n",
    "save_outputs = True  # true to save figures/movies to user's figure directory\n",
    "format = 'png'  # figure format ('png' | 'jpeg' | 'pdf'); movies saved as mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot train and val losses as a function of epochs\n",
    "Note: plots similar to these can be automatically saved upon completion of CAE training by setting the `export_train_plots` option to `True` in the training json file.\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from behavenet.fitting.utils import read_session_info_from_csv\n",
    "\n",
    "# set model info\n",
    "hparams = {\n",
    "    'data_dir': get_user_dir('data'),\n",
    "    'save_dir': get_user_dir('save'),\n",
    "    'experiment_name': 'ae-example',\n",
    "    'model_class': 'ae',\n",
    "    'model_type': 'conv',\n",
    "    'n_ae_latents': 9,\n",
    "}\n",
    "\n",
    "# programmatically fill out other hparams options\n",
    "get_lab_example(hparams, 'musall', 'vistrained')\n",
    "hparams['session_dir'], sess_ids = get_session_dir(hparams)\n",
    "hparams['expt_dir'] = get_expt_dir(hparams)\n",
    "\n",
    "# find metrics csv file\n",
    "versions = get_best_model_version(hparams['expt_dir'])\n",
    "version_dir = os.path.join(hparams['expt_dir'], 'version_%i' % versions[0])\n",
    "metric_file = os.path.join(version_dir, 'metrics.csv')\n",
    "metrics = pd.read_csv(metric_file)\n",
    "\n",
    "# collect data from csv file\n",
    "sess_ids = read_session_info_from_csv(os.path.join(version_dir, 'session_info.csv'))\n",
    "sess_ids_strs = []\n",
    "for sess_id in sess_ids:\n",
    "    sess_ids_strs.append(str('%s/%s' % (sess_id['animal'], sess_id['session'])))\n",
    "metrics_df = []\n",
    "for i, row in metrics.iterrows():\n",
    "    dataset = 'all' if row['dataset'] == -1 else sess_ids_strs[row['dataset']]\n",
    "    metrics_df.append(pd.DataFrame({\n",
    "        'dataset': dataset,\n",
    "        'epoch': row['epoch'],\n",
    "        'loss': row['val_loss'],\n",
    "        'dtype': 'val',\n",
    "    }, index=[0]))\n",
    "    metrics_df.append(pd.DataFrame({\n",
    "        'dataset': dataset,\n",
    "        'epoch': row['epoch'],\n",
    "        'loss': row['tr_loss'],\n",
    "        'dtype': 'train',\n",
    "    }, index=[0]))\n",
    "metrics_df = pd.concat(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data\n",
    "sns.set_style('white')\n",
    "sns.set_context('talk')\n",
    "\n",
    "data_queried = metrics_df[(metrics_df.epoch > 20) & ~pd.isna(metrics_df.loss)]\n",
    "splt = sns.relplot(x='epoch', y='loss', hue='dtype', kind='line', data=data_queried)\n",
    "splt.ax.set_xlabel('Epoch')\n",
    "splt.ax.set_yscale('log')\n",
    "splt.ax.set_ylabel('MSE per pixel')\n",
    "\n",
    "if save_outputs:\n",
    "    save_file = os.path.join(get_user_dir('fig'), 'ae', 'loss_vs_epoch')\n",
    "    make_dir_if_not_exists(save_file)\n",
    "    plt.savefig(save_file + '.' + format, dpi=300, format=format)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot train/val losses as a function of dataset\n",
    "In the previous section we plotted training and validation losses for a CAE trained on a single experimental session, which was defined by the call to `get_lab_example()`; this function uses the example dataset defined in the `.behavenet/musall_vistrained_params` json file (`05-Dec-2017`). To choose the other dataset, you can modify the above cell like so:\n",
    "```python\n",
    "...\n",
    "get_lab_example(hparams, 'musall', 'vistrained')\n",
    "hparams['session'] = '07-Dec-2017'  # <- add this line\n",
    "...\n",
    "```\n",
    "\n",
    "There is a third option, which is to plot performance of the model trained on both datasets simultaneously:\n",
    "```python\n",
    "...\n",
    "get_lab_example(hparams, 'musall', 'vistrained')\n",
    "hparams['session'] = 'multisession-00'\n",
    "...\n",
    "```\n",
    "\n",
    "The session name `multisession-00` is a bit cryptic - with many datasets, this would correspond to only one of many different combinations. The datasets which are associated with this multisession dataset can be found in the `session_info.csv` file inside the multisession directory, i.e. `save_dir/musall/vistrained/mSM36/multisession-00/session_info.csv`. \n",
    "\n",
    "Below we will plot CAE performance on both datasets throughout training. [Note that this CAE was trained using half the number of epochs as the previous one since there was twice as many batches when combining the datasets.]\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from behavenet.fitting.utils import read_session_info_from_csv\n",
    "\n",
    "# set model info\n",
    "hparams = {\n",
    "    'data_dir': get_user_dir('data'),\n",
    "    'save_dir': get_user_dir('save'),\n",
    "    'experiment_name': 'ae-example',\n",
    "    'model_class': 'ae',\n",
    "    'model_type': 'conv',\n",
    "    'n_ae_latents': 9,\n",
    "}\n",
    "\n",
    "# programmatically fill out other hparams options\n",
    "get_lab_example(hparams, 'musall', 'vistrained')\n",
    "hparams['session'] = 'multisession-00'\n",
    "hparams['session_dir'], sess_ids = get_session_dir(hparams)\n",
    "hparams['expt_dir'] = get_expt_dir(hparams)\n",
    "\n",
    "# find metrics csv file\n",
    "versions = get_best_model_version(hparams['expt_dir'])\n",
    "version_dir = os.path.join(hparams['expt_dir'], 'version_%i' % versions[0])\n",
    "metric_file = os.path.join(version_dir, 'metrics.csv')\n",
    "metrics = pd.read_csv(metric_file)\n",
    "\n",
    "# collect data from csv file\n",
    "sess_ids = read_session_info_from_csv(os.path.join(version_dir, 'session_info.csv'))\n",
    "sess_ids_strs = []\n",
    "for sess_id in sess_ids:\n",
    "    sess_ids_strs.append(str('%s/%s' % (sess_id['animal'], sess_id['session'])))\n",
    "metrics_df = []\n",
    "for i, row in metrics.iterrows():\n",
    "    dataset = 'Combined' if row['dataset'] == -1 else sess_ids_strs[row['dataset']]\n",
    "    metrics_df.append(pd.DataFrame({\n",
    "        'dataset': dataset,\n",
    "        'epoch': row['epoch'],\n",
    "        'loss': row['val_loss'],\n",
    "        'dtype': 'val',\n",
    "    }, index=[0]))\n",
    "    metrics_df.append(pd.DataFrame({\n",
    "        'dataset': dataset,\n",
    "        'epoch': row['epoch'],\n",
    "        'loss': row['tr_loss'],\n",
    "        'dtype': 'train',\n",
    "    }, index=[0]))\n",
    "metrics_df = pd.concat(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data\n",
    "sns.set_style('white')\n",
    "sns.set_context('talk')\n",
    "\n",
    "dtype = 'val'  # 'train' | 'val'\n",
    "data_queried = metrics_df[\n",
    "    (metrics_df.epoch > 20) & (metrics_df.dtype == dtype) & ~pd.isna(metrics_df.loss)]\n",
    "splt = sns.relplot(x='epoch', y='loss', hue='dataset', kind='line', data=data_queried)\n",
    "splt.ax.set_xlabel('Epoch')\n",
    "splt.ax.set_yscale('log')\n",
    "splt.ax.set_ylabel('MSE per pixel')\n",
    "# plt.title('%s loss' % title_str)\n",
    "\n",
    "if save_outputs:\n",
    "    save_file = os.path.join(get_user_dir('fig'), 'ae', 'loss_vs_epoch_by_dataset')\n",
    "    make_dir_if_not_exists(save_file)\n",
    "    plt.savefig(save_file + '.' + format, dpi=300, format=format)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make reconstruction movies\n",
    "The above plots are useful, for example, if you want to determine whether or not the model training completed satisfactorily. They are not useful, however, in understanding how good the reconstructions actually look. In order to do so BehaveNet has functionality to make reconstruction movies that contain the original video, the reconstructed video, and the residual.\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from behavenet.plotting.ae_utils import make_ae_reconstruction_movie_wrapper\n",
    "from behavenet.data.utils import get_data_generator_inputs\n",
    "from behavenet.data.data_generator import ConcatSessionsGenerator\n",
    "\n",
    "# movie info\n",
    "save_outputs = True\n",
    "include_linear = False  # True to include reconstructions from linear models; need training\n",
    "\n",
    "# set model info\n",
    "version = 'best'  # test-tube version; 'best' finds the version with the lowest mse\n",
    "sess_idx = 0  # when using a multisession, this determines which session is used\n",
    "hparams = {\n",
    "    'data_dir': get_user_dir('data'),\n",
    "    'save_dir': get_user_dir('save'),\n",
    "    'experiment_name': 'ae-example',\n",
    "    'lin_experiment_name': 'ae-example',\n",
    "    'model_class': 'ae',\n",
    "    'model_type': 'conv',\n",
    "    'n_ae_latents': 9,\n",
    "    'frame_rate': 20,  # frame rate of rendered movie, not original behavioral video\n",
    "}\n",
    "\n",
    "# programmatically fill out other hparams options\n",
    "get_lab_example(hparams, 'musall', 'vistrained')   \n",
    "hparams['session_dir'], sess_ids = get_session_dir(hparams)\n",
    "hparams['expt_dir'] = get_expt_dir(hparams)\n",
    "\n",
    "# load data generator to find a test trial\n",
    "hparams, signals, transforms, paths = get_data_generator_inputs(hparams, sess_ids)\n",
    "data_generator = ConcatSessionsGenerator(\n",
    "    hparams['data_dir'], sess_ids, \n",
    "    signals_list=signals, transforms_list=transforms, paths_list=paths,\n",
    "    device='cpu', as_numpy=False, batch_load=True, rng_seed=0)\n",
    "print(data_generator)\n",
    "trial = data_generator.datasets[sess_idx].batch_idxs['test'][2]  # trial to use in movie\n",
    "\n",
    "filename = str('D=%02i_recon_ae' % hparams['n_ae_latents'])\n",
    "if include_linear:\n",
    "    filename += '_wlinear'\n",
    "\n",
    "make_ae_reconstruction_movie_wrapper(\n",
    "    hparams, version=version, \n",
    "    save_file=os.path.join(get_user_dir('fig'), 'ae', filename), \n",
    "    include_linear=include_linear, trial=trial)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "behavenet",
   "language": "python",
   "name": "behavenet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
