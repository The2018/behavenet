{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and analyze ARHMMs\n",
    "The next step of the BehaveNet pipeline is to model the low-dimensional representation of behavior with a simple class of nonlinear dynamical systems called autoregressive hidden Markov models (ARHMMs). An ARHMM models the sequence of continuous latents as a stochastic process that switches between a small number *K* of discrete states, each characterized by linear-Gaussian dynamics. These discrete state variables also exhibit temporal dependences through Markovian dynamics - the discrete state at time *t* may depend on its preceding value.\n",
    "\n",
    "This model posits that the animal's behavior is composed of a small number (*K*) of discrete \"behavioral syllables\", such that many complex behaviors can be decomposed into sequences of these simpler syllables [[Wiltschko et al 2015](https://www.sciencedirect.com/science/article/pii/S0896627315010375), [Markowitz et al 2018](https://www.sciencedirect.com/science/article/pii/S0092867418305129)]. This notebook will guide you through fitting ARHMMs with BehaveNet (using the `ssm` package as the backend) and analyzing basic properties of the fitted models.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Contents\n",
    "* [Fitting ARHMMs](#Fitting-ARHMMs)\n",
    "* [Plot validation log probability as a function of discrete states](#Plot-validation-log-probability-as-a-function-of-discrete-states)\n",
    "* [Visualize state segmentations for multiple trials](#Visualize-state-segmentations-for-multiple-trials)\n",
    "* [Plot inferred and generated latents and states](#Plot-inferred-and-generated-latents-and-states)\n",
    "* [Make real vs generated movies](#Make-real-vs-generated-movies)\n",
    "* [Make syllable movies](#Make-syllable-movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from behavenet import get_user_dir, make_dir_if_not_exists\n",
    "from behavenet.data.utils import get_transforms_paths\n",
    "from behavenet.data.utils import load_labels_like_latents\n",
    "from behavenet.fitting.utils import get_expt_dir\n",
    "from behavenet.fitting.utils import get_session_dir\n",
    "from behavenet.fitting.utils import get_best_model_version\n",
    "from behavenet.fitting.utils import get_lab_example\n",
    "from behavenet.plotting.arhmm_utils import *\n",
    "\n",
    "save_outputs = True  # true to save figures/movies to user's figure directory\n",
    "format = 'png'  # figure format ('png' | 'jpeg' | 'pdf'); movies saved as mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting ARHMMs\n",
    "\n",
    "Fitting a single ARHMM is very similar to the AE fitting procedure; first copy the example json files ``arhmm_compute.json``, ``arhmm_model.json``, and ``arhmm_training.json`` into your ``.behavenet`` directory, ``cd`` to the ``behavenet`` directory in the terminal, and run:\n",
    "\n",
    "```console\n",
    "$: python behavenet/fitting/arhmm_grid_search.py --data_config ~/.behavenet/musall_vistrained_params.json --model_config ~/.behavenet/arhmm_model.json --training_config ~/.behavenet/arhmm_training.json --compute_config ~/.behavenet/arhmm_compute.json\n",
    "```\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot validation log probability as a function of discrete states\n",
    "The number of discrete ARHMM states *K* is an important hyperparameter of the model. Though there is no one best way to choose *K*, a helpful diagnostic is to look at the log probability of the trained ARHMM on held-out validation data as a function of *K*.\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from behavenet.fitting.utils import get_subdirs\n",
    "\n",
    "# define which arhmm states to plot (must already be fit)\n",
    "n_arhmm_states = [2, 4, 8, 12]\n",
    "\n",
    "# set model info\n",
    "hparams = {\n",
    "    'data_dir': get_user_dir('data'),\n",
    "    'save_dir': get_user_dir('save'),\n",
    "    'experiment_name': 'state_number_search',\n",
    "    'model_class': 'arhmm',\n",
    "    'model_type': None,\n",
    "    'noise_type': 'gaussian',\n",
    "    'n_arhmm_lags': 1,\n",
    "    'kappa': 0,\n",
    "    'ae_experiment_name': 'ae-example',\n",
    "    'n_ae_latents': 9,\n",
    "}\n",
    "get_lab_example(hparams, 'musall', 'vistrained')\n",
    "\n",
    "metrics_df = []\n",
    "for n_states in n_arhmm_states:\n",
    "    hparams['n_arhmm_states'] = n_states\n",
    "    hparams['session_dir'], _ = get_session_dir(hparams)\n",
    "    expt_dir = get_expt_dir(hparams)\n",
    "    # gather all versions\n",
    "    try:\n",
    "        versions = get_subdirs(expt_dir)\n",
    "    except Exception:\n",
    "        print('No models in %s; skipping' % expt_dir)\n",
    "        continue\n",
    "    # load csv files with model metrics (saved out from test tube)\n",
    "    for i, version in enumerate(versions):\n",
    "        # read metrics csv file\n",
    "        model_dir = os.path.join(expt_dir, version)\n",
    "        try:\n",
    "            metrics = pd.read_csv(os.path.join(model_dir, 'metrics.csv'))\n",
    "        except:\n",
    "            continue\n",
    "        with open(os.path.join(model_dir, 'meta_tags.pkl'), 'rb') as f:\n",
    "            hp_new = pickle.load(f)\n",
    "        if not hp_new['training_completed']:\n",
    "            continue\n",
    "        for i, row in metrics.iterrows():\n",
    "            if 'test_loss' in row:\n",
    "                metrics_df.append(pd.DataFrame({\n",
    "                    'epoch': row['epoch'],\n",
    "                    'loss': row['test_loss'],\n",
    "                    'n_states': n_states}, index=[0]))\n",
    "metrics_df = pd.concat(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data\n",
    "sns.set_style('white')\n",
    "sns.set_context('talk')\n",
    "\n",
    "splt = sns.relplot(x='n_states', y='loss', hue=None, kind='line', data=metrics_df)\n",
    "splt.ax.set_xlabel('ARHMM states')\n",
    "splt.ax.set_xscale('log')\n",
    "splt.ax.set_xticks(n_arhmm_states)\n",
    "splt.ax.set_xticklabels(n_arhmm_states)\n",
    "splt.ax.set_ylabel('Log prob per frame')\n",
    "\n",
    "if save_outputs:\n",
    "    filename = os.path.join(get_user_dir('fig'), hparams['model_class'], 'll_vs_states')\n",
    "    make_dir_if_not_exists(filename)\n",
    "    plt.savefig(filename + '.' + format, dpi=300, format=format)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize state segmentations for multiple trials\n",
    "Another useful visualization is to plot ARHMM state segmentations over multiple trials, where each time point is colored based on the discrete state assigned by the ARHMM.\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_segmentations_by_trial(\n",
    "        states, xtick_locs=None, xticklabel_offset=0, frame_rate=None, save_file=None, \n",
    "        title=None, cmap='tab20b'):\n",
    "\n",
    "    from matplotlib.lines import Line2D\n",
    "\n",
    "    n_trials = len(states)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, n_trials / 4))\n",
    "    gs_bottom_left = plt.GridSpec(n_trials, 1, top=0.85, right=1)\n",
    "    for i_trial in range(n_trials):\n",
    "\n",
    "        axes = plt.subplot(gs_bottom_left[i_trial, 0])\n",
    "        axes.imshow(\n",
    "            states[i_trial][None, :], aspect='auto',\n",
    "            extent=(0, len(states[i_trial]), 0, 1), cmap=cmap, alpha=0.8)\n",
    "        axes.set_xticks([])\n",
    "        axes.set_yticks([])\n",
    "        axes.set_frame_on(False)\n",
    "\n",
    "    if xtick_locs is not None and frame_rate is not None:\n",
    "        axes.set_xticks(xtick_locs)\n",
    "        axes.set_xticklabels(\n",
    "            ((xticklabel_offset + np.asarray(xtick_locs)) / frame_rate).astype('int'))\n",
    "        axes.set_xlabel('Time (s)')\n",
    "    else:\n",
    "        axes.set_xlabel('Time (bins)')\n",
    "    axes = plt.subplot(gs_bottom_left[int(np.floor(n_trials / 2)), 0])\n",
    "    axes.set_ylabel('Trials')\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_file is not None:\n",
    "        make_dir_if_not_exists(save_file)\n",
    "        fig.savefig(save_file, transparent=True, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user params\n",
    "get_best_version = True  # False when looking at multiple models w/in a tt expt\n",
    "dtype = 'test'  # data type to draw trials from: 'train' | 'val' | 'test'\n",
    "sess_idx = 0  # when using a multisession, this determines which session is used\n",
    "max_frames = 200\n",
    "\n",
    "# define which arhmm states to plot (must already be fit)\n",
    "n_arhmm_states = [2, 4]\n",
    "\n",
    "# set model info\n",
    "hparams = {\n",
    "    'data_dir': get_user_dir('data'),\n",
    "    'save_dir': get_user_dir('save'),\n",
    "    'experiment_name': 'state_number_search',\n",
    "    'model_class': 'arhmm',\n",
    "    'model_type': None,\n",
    "    'noise_type': 'gaussian',\n",
    "    'n_arhmm_lags': 1,\n",
    "    'kappa': 0,\n",
    "    'ae_experiment_name': 'ae-example',\n",
    "    'ae_model_type': 'conv',\n",
    "    'n_ae_latents': 9,\n",
    "}\n",
    "get_lab_example(hparams, 'musall', 'vistrained')\n",
    "\n",
    "xtick_locs = [0, 30, 60, 90, 120, 150, 180]\n",
    "frame_rate = 30\n",
    "n_trials = 20\n",
    "           \n",
    "for n_states in n_arhmm_states:\n",
    "        \n",
    "    hparams['n_arhmm_states'] = n_states\n",
    "    hparams['session_dir'], sess_ids = get_session_dir(hparams)\n",
    "    hparams['expt_dir'] = get_expt_dir(hparams)\n",
    "\n",
    "    # get version/model\n",
    "    if get_best_version:\n",
    "        version = get_best_model_version(\n",
    "            hparams['expt_dir'], measure='val_loss', best_def='max')[0]\n",
    "    else:\n",
    "        _, version = experiment_exists(hparams, which_version=True)\n",
    "\n",
    "    # load model\n",
    "    model_file = os.path.join(\n",
    "        hparams['expt_dir'], 'version_%i' % version, 'best_val_model.pt')\n",
    "    with open(model_file, 'rb') as f:\n",
    "        hmm = pickle.load(f)\n",
    "\n",
    "    if hparams['model_class'] == 'arhmm':\n",
    "            \n",
    "        # load latents\n",
    "        _, latents_file = get_transforms_paths('ae_latents', hparams, sess_ids[sess_idx])\n",
    "        with open(latents_file, 'rb') as f:\n",
    "            all_latents = pickle.load(f)\n",
    "            \n",
    "        model_name = str(\n",
    "            'multitrial_segmentation_D=%02i_K=%02i' % (\n",
    "            hparams['n_ae_latents'], hparams['n_arhmm_states']))\n",
    "            \n",
    "    elif hparams['model_class'] == 'arhmm-labels':\n",
    "        \n",
    "        from behavenet.data.utils import load_labels_like_latents\n",
    "        \n",
    "        # load labels\n",
    "        hparams['device'] = 'cpu'\n",
    "        hparams['as_numpy'] = True\n",
    "        hparams['batch_load'] = True\n",
    "        hparams['rng_seed_data'] = 0\n",
    "        hparams['trial_splits'] = '8;1;1;0'\n",
    "        hparams['train_frac'] = 1.0\n",
    "        all_latents = load_labels_like_latents(hparams, sess_ids, sess_idx)\n",
    "        model_name = str('multitrial_segmentation_K=%02i' % hparams['n_arhmm_states'])\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # choose which trials to plot\n",
    "    np.random.seed(0)\n",
    "    trial_vec = np.random.choice(\n",
    "        np.arange(0, len(all_latents['trials'][dtype])), size=(n_trials,), \n",
    "        replace=False)\n",
    "\n",
    "    # collect states\n",
    "    trial_idxs = {}\n",
    "    latents = {}\n",
    "    states = {}\n",
    "    for data_type in [dtype]:\n",
    "        trial_idxs[data_type] = all_latents['trials'][data_type]\n",
    "        latents[data_type] = [\n",
    "            all_latents['latents'][i_trial] for i_trial in trial_idxs[data_type]]\n",
    "        states[data_type] = [\n",
    "            np.full((max_frames,), fill_value=np.nan) for _ in latents[data_type]]\n",
    "        for i, j in enumerate(trial_vec):\n",
    "            x = latents[data_type][j][:max_frames]\n",
    "            states_tmp = hmm.most_likely_states(x)\n",
    "            n_frames = len(states_tmp)\n",
    "            states[data_type][j][:n_frames] = states_tmp\n",
    "\n",
    "    if save_outputs:\n",
    "        save_file = os.path.join(\n",
    "            get_user_dir('fig'), hparams['model_class'], model_name + '.' + format)\n",
    "    else:\n",
    "        save_file = None\n",
    "\n",
    "    fig = plot_segmentations_by_trial(\n",
    "        [states[dtype][t] for t in trial_vec], xtick_locs,  \n",
    "        0, frame_rate, save_file=save_file, title=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot inferred and generated latents and states\n",
    "The ARHMM is a fully probabilistic model, which means that we can generate synthetic data from it. For example, we can sample a path of the Markov chain, and use these discrete states to generate observations (CAE latents) from the learned linear-Gaussian dynamics.\n",
    "\n",
    "Comparing inferred CAE latents and ARHMM states with those generated from the model can be a useful way to understand if the ARHMM is indeed a good generative model of the data.\n",
    "\n",
    "There are two ways to generate data from the ARHMM:\n",
    "* **conditional sampling**: Generated data is conditioned on the most likely discrete states inferred from a batch of data. This tests how well the learned linear-Gaussian dynamics fit the data.\n",
    "* **unconditional sampling**: A discrete state sequence is first sampled from the learned Markov chain, and then the generated data is conditioned on this states sequence. This additionally tests how well the Markov transition matrix has learned the statistical structure of switching in the data.\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from behavenet.plotting.arhmm_utils import get_model_latents_states\n",
    "from behavenet.plotting.arhmm_utils import plot_states_overlaid_with_latents\n",
    "\n",
    "# user params\n",
    "sess_idx = 0  # when using a multisession, this determines which session is used\n",
    "version = ''  # test-tube version; 'best' finds the version with the lowest mse\n",
    "\n",
    "xtick_locs = [0, 30, 60, 90, 120, 150, 180]\n",
    "frame_rate = 30\n",
    "max_frames = 200\n",
    "\n",
    "# set model info\n",
    "hparams = {\n",
    "    'data_dir': get_user_dir('data'),\n",
    "    'save_dir': get_user_dir('save'),\n",
    "    'experiment_name': 'state_number_search',\n",
    "    'model_class': 'arhmm',\n",
    "    'model_type': None,\n",
    "    'n_arhmm_states': 4,\n",
    "    'noise_type': 'gaussian',\n",
    "    'n_arhmm_lags': 1,\n",
    "    'kappa': 0,\n",
    "    'ae_experiment_name': 'ae-example',\n",
    "    'ae_model_type': 'conv',\n",
    "    'ae_version': 'best',\n",
    "    'n_ae_latents': 9,\n",
    "    'rng_seed_data': 0,\n",
    "    'rng_seed_model': 0,\n",
    "    'train_frac': 1.0,\n",
    "    'trial_splits': '8;1;1;0'\n",
    "}\n",
    "get_lab_example(hparams, 'musall', 'vistrained')\n",
    "\n",
    "np.random.seed(101)\n",
    "\n",
    "# cond_sampling: True to condition samples on inferred discrete states of real data\n",
    "for cond_sampling in [True, False]:\n",
    "    save_str = 'conditional' if cond_sampling else 'unconditional'\n",
    "    save_file = os.path.join(\n",
    "        get_user_dir('fig'), 'arhmm', 'infer_vs_sample_%s_D=%02i_K=%02i' % (\n",
    "            save_str, hparams['n_ae_latents'], hparams['n_arhmm_states']))\n",
    "    fig = real_vs_sampled_wrapper(\n",
    "        'both', hparams, save_file, 0, xtick_locs=xtick_locs, max_frames=max_frames,\n",
    "        frame_rate=frame_rate, frame_rate_beh=frame_rate, conditional=cond_sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make syllable movies\n",
    "If many behaviors can indeed be decomposed into a sequence of simpler actions we might hope these are represented by the ARHMM discrete states. A useful, *qualitative* way to gauge interpretability of the ARHMM discrete states is to watch clips of the original behavioral video during all times when the animal is in, say, state *k*.\n",
    "\n",
    "The following cell will take all data of a certain type (training, validation, or testing), and for each discrete state extract all time windows when that state is in the most likely state sequence. The behavioral video for these time windows (as well as a small number of buffer frames before state onset) is then animated, with different time windows separated by a few blank frames.\n",
    "\n",
    "This process is repeated for each discrete state, and all discrete states are animated simultaneously, each in their own subplot (though movies can be made one state at a time - see `make_syllable_movies_wrapper()` documentation).\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from behavenet.plotting.arhmm_utils import make_syllable_movies_wrapper\n",
    "\n",
    "# user params\n",
    "dtype = 'train'  # data type to draw trials from: 'train' | 'val' | 'test'\n",
    "sess_idx = 0  # when using a multisession, this determines which session is used\n",
    "\n",
    "# set model info\n",
    "hparams = {\n",
    "    'data_dir': get_user_dir('data'),\n",
    "    'save_dir': get_user_dir('save'),\n",
    "    'experiment_name': 'state_number_search',\n",
    "    'model_class': 'arhmm',\n",
    "    'model_type': None,\n",
    "    'n_arhmm_states': 4,\n",
    "    'noise_type': 'gaussian',\n",
    "    'n_arhmm_lags': 1,\n",
    "    'kappa': 0,\n",
    "    'ae_experiment_name': 'ae-example',\n",
    "    'ae_model_type': 'conv',\n",
    "    'ae_version': 'best',\n",
    "    'n_ae_latents': 9,\n",
    "    'rng_seed_data': 0,\n",
    "    'rng_seed_model': 0,\n",
    "    'train_frac': 1.0,\n",
    "    'trial_splits': '8;1;1;0'\n",
    "}\n",
    "\n",
    "# programmatically fill out other hparams options\n",
    "get_lab_example(hparams, 'musall', 'vistrained') \n",
    "\n",
    "save_file = os.path.join(\n",
    "    get_user_dir('fig'), hparams['model_class'], 'syllable-movies_D=%02i_K=%02i' % \n",
    "    (hparams['n_ae_latents'], hparams['n_arhmm_states']))\n",
    "make_syllable_movies_wrapper(hparams, save_file, sess_idx=sess_idx, n_rows=1, dtype=dtype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "behavenet",
   "language": "python",
   "name": "behavenet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
