{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze a PS-VAE model\n",
    "Because the PS-VAEs currently require significant computation time (generally ~5 hours on a GPU) the data downloaded in the previous notebook also contains already trained PS-VAEs, which we will analyze here.\n",
    "\n",
    "There are a variety of files that are automatically saved during the fitting of a PS-VAE, which can be used for later analyses such as those below. Some of these files (many of which are common to all BehaveNet models, not just the PS-VAE):\n",
    "* `best_val_model.pt`: the best PS-VAE (not necessarily from the final training epoch) as determined by computing the loss on validation data\n",
    "* `meta_tags.csv`: hyperparameters associated with data, computational resources, and model\n",
    "* `metrics.csv`: metrics computed on dataset as a function of epochs; the default is that metrics are computed on training and validation data every epoch (and reported as a mean over all batches) while metrics are computed on test data only at the end of training using the best model (and reported per batch).\n",
    "* `[lab_id]_[expt_id]_[animal_id]_[session_id]_latents.pkl`: list of np.ndarrays of PS-VAE latents (both supervised and unsupervised) computed using the best model\n",
    "* `session_info.csv`: sessions used to fit the model\n",
    "\n",
    "To fit your own PS-VAEs, see additional documentation [here](https://behavenet.readthedocs.io/en/latest/source/user_guide.html).\n",
    "\n",
    "<br>\n",
    "\n",
    "### Contents\n",
    "* [Plot validation losses as a function of epochs](#Plot-losses-as-a-function-of-epochs)\n",
    "* [Plot label reconstructions](#Plot-label-reconstructions)\n",
    "* [Plot latent traversals](#Plot-latent-traversals)\n",
    "* [Make latent traversal movie](#Make-latent-traversal-movie)\n",
    "* [Make frame reconstruction movie](#Make-reconstruction-movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from behavenet import get_user_dir\n",
    "from behavenet.plotting.cond_ae_utils import plot_psvae_training_curves\n",
    "from behavenet.plotting.cond_ae_utils import plot_label_reconstructions\n",
    "from behavenet.plotting.cond_ae_utils import plot_latent_traversals\n",
    "from behavenet.plotting.cond_ae_utils import make_latent_traversal_movie\n",
    "\n",
    "# ONLY NEED TO CHANGE THIS LINE\n",
    "# 'head-fixed': IBL data\n",
    "# 'mouse-face': dipoppa data\n",
    "# 'two-view': musall data\n",
    "# 'freely-moving': rodriguez data\n",
    "dataset = 'head-fixed'\n",
    "\n",
    "save_outputs = True  # true to save figures/movies to user's figure directory\n",
    "file_ext = 'pdf'  # figure format ('png' | 'jpeg' | 'pdf'); movies saved as mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define dataset parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters common to all datasets\n",
    "\n",
    "# number of unsupervised latents\n",
    "n_latents = 2\n",
    "\n",
    "# some models trained with 50% of training data to speed up fitting\n",
    "train_frac = 1 if dataset == 'freely-moving' else 0.5\n",
    "\n",
    "# test-tube experiment name\n",
    "experiment_name = 'demo-run'\n",
    "\n",
    "# set dataset-specific parameters\n",
    "if dataset == 'head-fixed':\n",
    "    \n",
    "    lab = 'ibl'\n",
    "    expt = 'angelakilab'\n",
    "    animal = 'IBL-T4'\n",
    "    session = '2019-04-23-001'\n",
    "    n_labels = 4\n",
    "    label_names = ['L paw (x)', 'R paw (x)', 'L paw (y)', 'R paw (y)']\n",
    "\n",
    "    # define \"best\" model\n",
    "    best_alpha = 1000\n",
    "    best_beta = 5\n",
    "    best_gamma = 500\n",
    "    best_rng = 0\n",
    "\n",
    "    # label reconstructions\n",
    "    label_recon_trials= [229, 289, 419]  # good validation trials; also used for frame recon\n",
    "    xtick_locs= [0, 30, 60, 90]\n",
    "    frame_rate= 60\n",
    "    scale= 0.4\n",
    "        \n",
    "    # latent traversal params\n",
    "    label_min_p = 35  # lower bound of label traversals\n",
    "    label_max_p = 85  # upper bound of label traversals\n",
    "    ch = 0  # video channel to display\n",
    "    n_frames_zs = 4  # n frames for supervised static traversals\n",
    "    n_frames_zu = 4  # n frames for unsupervised static traversals\n",
    "    label_idxs = [1, 0]  # horizontally move left/right paws\n",
    "    crop_type = None  # no image cropping\n",
    "    crop_kwargs = None  # no image cropping\n",
    "    # select base frames for traversals\n",
    "    trial_idxs = [11, 4, 0, None, None, None, None]  # trial index wrt to all test trials\n",
    "    trials = [None, None, None, 169, 129, 429, 339]  # trial index wrt to *all* trials\n",
    "    batch_idxs = [99, 99, 99, 16, 46, 11, 79]  # batch index within trial\n",
    "    n_cols = 3  # width of traversal movie\n",
    "    text_color = [1, 1, 1]  # text color for labels\n",
    "    \n",
    "elif dataset == 'mouse-face':\n",
    "    \n",
    "    lab = 'dipoppa'\n",
    "    expt = 'pupil'\n",
    "    animal = 'MD0ST5'\n",
    "    session = 'session-3'\n",
    "    n_labels = 3\n",
    "    label_names = ['Pupil area', 'Pupil (y)', 'Pupil (x)']\n",
    "\n",
    "    # define \"best\" model\n",
    "    best_alpha = 1000\n",
    "    best_beta = 20\n",
    "    best_gamma = 1000\n",
    "    best_rng = 0\n",
    "\n",
    "    # label reconstructions\n",
    "    label_recon_trials= [43, 83, 73]  # good validation trials; also used for frame recon\n",
    "    xtick_locs= [0, 30, 60, 90, 120, 150]\n",
    "    frame_rate= 30\n",
    "    scale= 0.45\n",
    "        \n",
    "    # latent traversal params\n",
    "    label_min_p = 5  # lower bound of label traversals\n",
    "    label_max_p = 95  # upper bound of label traversals\n",
    "    ch = 0  # video channel to display\n",
    "    n_frames_zs = 4  # n frames for supervised static traversals\n",
    "    n_frames_zu = 4  # n frames for unsupervised static traversals\n",
    "    label_idxs = [1, 2]  # pupil location\n",
    "    crop_type = 'fixed'  # crop around eye\n",
    "    crop_kwargs = {'y_0': 48, 'y_ext': 48, 'x_0': 192, 'x_ext': 64}\n",
    "    # select base frames for traversals\n",
    "    trial_idxs = [11, None, 21]  # trial index wrt to all test trials\n",
    "    trials = [None, 393, None]  # trial index wrt to *all* trials\n",
    "    batch_idxs = [60, 27, 99]  # batch index within trial\n",
    "    n_cols = 3  # width of traversal movie\n",
    "    text_color = [0, 0, 0]  # text color for labels\n",
    "    \n",
    "elif dataset == 'two-view':\n",
    "    \n",
    "    lab = 'musall'\n",
    "    expt = 'vistrained'\n",
    "    animal = 'mSM36'\n",
    "    session = '05-Dec-2017-wpaw'\n",
    "    n_labels = 5\n",
    "    label_names = ['Levers', 'L Spout', 'R Spout', 'R paw (x)', 'R paw (y)']\n",
    "\n",
    "    # define \"best\" model\n",
    "    best_alpha = 1000\n",
    "    best_beta = 1\n",
    "    best_gamma = 1000\n",
    "    best_rng = 1\n",
    "\n",
    "    # label reconstructions\n",
    "    label_recon_trials= [9, 19, 29]  # good validation trials; also used for frame recon\n",
    "    xtick_locs= [0, 60, 120, 180]\n",
    "    frame_rate= 30\n",
    "    scale= 0.25\n",
    "\n",
    "    # latent traversal params\n",
    "    label_min_p = 5  # lower bound of label traversals\n",
    "    label_max_p = 95  # upper bound of label traversals\n",
    "    ch = 1  # video channel to display\n",
    "    n_frames_zs = 3  # n frames for supervised static traversals\n",
    "    n_frames_zu = 3  # n frames for unsupervised static traversals\n",
    "    label_idxs = [3, 4]  # move right paw\n",
    "    crop_type = None  # no image cropping\n",
    "    crop_kwargs = None  # no image cropping\n",
    "    # select base frames for traversals\n",
    "    trial_idxs = [11, 11, 11, 5]  # trial index wrt to all test trials\n",
    "    trials = [None, None, None, None]  # trial index wrt to *all* trials\n",
    "    batch_idxs = [99, 0, 50, 180]  # batch index within trial\n",
    "    n_cols = 2  # width of traversal movie\n",
    "    text_color = [1, 1, 1]  # text color for labels\n",
    "    \n",
    "elif dataset == 'freely-moving':\n",
    "    \n",
    "    lab = 'rodriguez'\n",
    "    expt = 'open-field'\n",
    "    animal = 'B125'\n",
    "    session = 'session-1'\n",
    "    n_labels = 8\n",
    "    label_names = [\n",
    "        'L ear (x)', 'R ear (x)', 'Back (x)', 'Tail base (x)', 'Nose (x)',\n",
    "        'R ear (y)', 'Back (y)', 'Nose (y)']\n",
    "\n",
    "    # define \"best\" model\n",
    "    best_alpha = 100\n",
    "    best_beta = 5\n",
    "    best_gamma = 1000\n",
    "    best_rng = 0\n",
    "\n",
    "    # label reconstructions\n",
    "    label_recon_trials = [9, 19, 29]  # good validation trials; also used for frame recon\n",
    "    xtick_locs = [0, 30, 60, 90, 120]\n",
    "    frame_rate = 30\n",
    "    scale = 0.4\n",
    "        \n",
    "    # latent traversal params\n",
    "    label_min_p = 35  # lower bound of label traversals\n",
    "    label_max_p = 85  # upper bound of label traversals\n",
    "    ch = 0  # video channel to display\n",
    "    n_frames_zs = 4  # n frames for supervised static traversals\n",
    "    n_frames_zu = 4  # n frames for unsupervised static traversals\n",
    "    label_idxs = [2, 4]  # move back, nose\n",
    "    crop_type = None  # no image cropping\n",
    "    crop_kwargs = None  # no image cropping\n",
    "    # select base frames for traversals\n",
    "    trial_idxs = [None, None, None, None]  # trial index wrt to all test trials\n",
    "    trials = [106, 60, 98, 32]  # trial index wrt to *all* trials\n",
    "    batch_idxs = [38, 24, 29, 123]  # batch index within trial\n",
    "    n_cols = 5  # width of traversal movie\n",
    "    text_color = [0, 0, 0]  # text color for labels\n",
    "\n",
    "else:\n",
    "    raise ValueError(\n",
    "        'Invalid dataset; must choose \"head-fixed\", \"mouse-face\", \"two-view\", or \"freely-moving\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot losses as a function of epochs\n",
    "The PS-VAE loss function contains many individual terms; this function plots each term separately (as well as the overall loss) to better understand model performance. Note that this function can also be used to plot training curves for multiple models simultaneously; see function documentation. \n",
    "\n",
    "Panel info (see paper for mathematical descriptions):\n",
    "* loss=loss: total PS-VAE loss\n",
    "* loss=loss_data_mse: mean square error on frames (actual loss function uses log-likelihood, a scaled version of the MSE)\n",
    "* loss=label_r2: $R^2$ (per trial) of the label reconstructions (actual loss function uses log-likelihood)\n",
    "* loss=loss_zs_kl: Kullback-Leibler (KL) divergence of supervised latents\n",
    "* loss=loss_zu_mi: index-code mutual information of unuspervised latents\n",
    "* loss=loss_zu_tc: total correlation of unuspervised latents\n",
    "* loss=loss_zu_dwkl: dimension-wise KL of unuspervised latents\n",
    "* loss=loss_AB_orth: orthogonality between supervised/unsupervised subspaces\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = os.path.join(\n",
    "    get_user_dir('fig'), lab, expt, animal, session, 'ps-vae', 'training_curves')\n",
    "\n",
    "save_file_new = save_file + '_alpha={}_beta={}_gamma={}_rng={}_latents={}'.format(\n",
    "    best_alpha, best_beta, best_gamma, best_rng, n_latents)\n",
    "plot_psvae_training_curves(\n",
    "    lab=lab, expt=expt, animal=animal, session=session, alphas=[best_alpha], \n",
    "    betas=[best_beta], n_ae_latents=[n_latents], \n",
    "    rng_seeds_model=[best_rng], experiment_name=experiment_name,\n",
    "    n_labels=n_labels, train_frac=train_frac,\n",
    "    save_file=save_file_new, format=file_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot label reconstructions\n",
    "Plot the original labels and their reconstructions from the supervised subspace of the PS-VAE.\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = os.path.join(\n",
    "    get_user_dir('fig'), lab, expt, animal, session, 'ps-vae', 'label_recon')\n",
    "\n",
    "plot_label_reconstructions(\n",
    "    lab=lab, expt=expt, animal=animal, session=session, n_ae_latents=n_latents, \n",
    "    experiment_name=experiment_name,\n",
    "    n_labels=n_labels, trials=label_recon_trials, version=None,\n",
    "    alpha=best_alpha, beta=best_beta, rng_seed_model=best_rng, \n",
    "    train_frac=train_frac, add_r2=False, save_file=save_file, format=file_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot latent traversals\n",
    "Latent traversals provide a qualitative way to assess the quality of the learned PS-VAE representation. We generate these traversals by changing the latent representation one dimension at a time and visually compare the outputs. If the representation is sufficiently interpretable we should be able to easily assign semantic meaning to each latent dimension.\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_latents = 2\n",
    "\n",
    "# for trial, trial_idx, batch_idx in zip(trials, trial_idxs, batch_idxs):\n",
    "# just plot traversals for single base frame\n",
    "trial = trials[0]\n",
    "trial_idx = trial_idxs[0]\n",
    "batch_idx = batch_idxs[0]\n",
    "\n",
    "if trial is not None:\n",
    "    trial_str = 'trial-%i-%i' % (trial, batch_idx)\n",
    "else:\n",
    "    trial_str = 'trial-idx-%i-%i' % (trial_idx, batch_idx)\n",
    "\n",
    "save_file = os.path.join(\n",
    "    get_user_dir('fig'), lab, expt, animal, session, 'ps-vae', \n",
    "    'traversals_alpha={}_beta={}_gamma={}_rng={}_latents={}_{}'.format(\n",
    "    best_alpha, best_beta, best_gamma, best_rng, n_latents, trial_str))\n",
    "\n",
    "plot_latent_traversals(\n",
    "    lab=lab, expt=expt, animal=animal, session=session, model_class='ps-vae', \n",
    "    alpha=best_alpha, beta=best_beta, n_ae_latents=2, \n",
    "    rng_seed_model=best_rng, experiment_name=experiment_name, \n",
    "    n_labels=n_labels, label_idxs=label_idxs,\n",
    "    label_min_p=label_min_p, label_max_p=label_max_p, channel=ch, \n",
    "    n_frames_zs=n_frames_zs, n_frames_zu=n_frames_zu, trial_idx=trial_idx, \n",
    "    trial=trial, batch_idx=batch_idx, crop_type=crop_type, crop_kwargs=crop_kwargs,\n",
    "    train_frac=train_frac, save_file=save_file, format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make latent traversal movie\n",
    "A dynamic version of the traversals above; these typically provide a richer look at the traversal results.\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = 10  # number of sample frames per dimension\n",
    "model_class = 'ps-vae'  # 'sss-vae' | 'vae'\n",
    "\n",
    "# NOTE: below I hand label each dimension; semantic labels for unsupervised dims are chosen\n",
    "# by looking at the latent traversals above, and are indicated with quotes to distinguish\n",
    "# them from the supervised dims\n",
    "\n",
    "if dataset == 'head-fixed':\n",
    "    if model_class == 'ps-vae':\n",
    "        panel_titles = label_names + ['\"Jaw\"', '\"L paw config\"']\n",
    "        order_idxs = [0, 1, 4, 2, 3, 5]  # reorder nicely\n",
    "    elif model_class == 'vae':\n",
    "        panel_titles = ['Latent %i' % i for i in range(n_labels + n_latents)]\n",
    "        order_idxs = [i for i in range(n_labels + n_latents)]\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "elif dataset == 'mouse-face':\n",
    "    if model_class == 'ps-vae':\n",
    "        panel_titles = label_names + ['\"Whisker pad\"', '\"Eyelid\"']\n",
    "        order_idxs = [2, 1, 0, 3, 4]  # reorder nicely\n",
    "    elif model_class == 'vae':\n",
    "        panel_titles = ['Latent %i' % i for i in range(n_labels + n_latents)]\n",
    "        order_idxs = [i for i in range(n_labels + n_latents)]\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "elif dataset == 'two-view':   \n",
    "    if model_class == 'ps-vae':\n",
    "        panel_titles = label_names + ['\"Chest\"', '\"Jaw\"']\n",
    "        order_idxs = [1, 2, 3, 4, 0, 5, 6]  # reorder nicely\n",
    "    elif model_class == 'vae':\n",
    "        panel_titles = ['Latent %i' % i for i in range(n_labels + n_latents)]\n",
    "        order_idxs = [i for i in range(n_labels + n_latents)]\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "elif dataset == 'freely-moving':   \n",
    "    if model_class == 'ps-vae':\n",
    "        panel_titles = label_names + ['\"Body posture 0\"', '\"Body posture 1\"']\n",
    "        order_idxs = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    elif model_class == 'vae':\n",
    "        panel_titles = ['Latent %i' % i for i in range(n_labels + n_latents)]\n",
    "        order_idxs = [i for i in range(n_labels + n_latents)]\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "save_file = os.path.join(\n",
    "    get_user_dir('fig'), lab, expt, animal, session, model_class, \n",
    "    'traversals_alpha={}_beta={}_gamma={}_rng={}_latents={}'.format(\n",
    "    best_alpha, best_beta, best_gamma, best_rng, n_latents))\n",
    "\n",
    "make_latent_traversal_movie(\n",
    "    lab=lab, expt=expt, animal=animal, session=session, model_class=model_class, \n",
    "    alpha=best_alpha, beta=best_beta, n_ae_latents=n_latents, \n",
    "    rng_seed_model=best_rng, experiment_name=experiment_name, \n",
    "    n_labels=n_labels, trial_idxs=trial_idxs, batch_idxs=batch_idxs, trials=trials, \n",
    "    panel_titles=panel_titles, label_min_p=label_min_p, \n",
    "    label_max_p=label_max_p, channel=ch, n_frames=n_frames, crop_kwargs=crop_kwargs, \n",
    "    n_cols=n_cols, movie_kwargs={'text_color': text_color}, order_idxs=order_idxs,\n",
    "    train_frac=train_frac, save_file=save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make reconstruction movies\n",
    "Compare original frames to VAE and PS-VAE reconstructions.\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from behavenet.plotting.ae_utils import make_reconstruction_movie\n",
    "from behavenet.plotting.cond_ae_utils import get_model_input\n",
    "from behavenet.fitting.eval import get_reconstruction\n",
    "from behavenet.fitting.utils import get_best_model_and_data, get_lab_example\n",
    "from behavenet.plotting import concat, save_movie\n",
    "\n",
    "def make_reconstruction_movie_wrapper(\n",
    "        hparams, save_file, model_info, trial_idxs=None, trials=None, sess_idx=0, \n",
    "        max_frames=400, frame_rate=15, layout_pattern=None):\n",
    "    \"\"\"Produce movie with original video and reconstructed videos.\n",
    "\n",
    "    This is a high-level function that loads the model described in the hparams dictionary \n",
    "    and produces the necessary predicted video frames.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    hparams : :obj:`dict`\n",
    "        needs to contain enough information to specify an autoencoder\n",
    "    save_file : :obj:`str`\n",
    "        full save file (path and filename)\n",
    "    model_info : :obj:`list`\n",
    "        each entry is a dict that contains model-specific parameters; must include\n",
    "        'title', 'model_class'\n",
    "    trial_idxs : :obj:`list`, optional\n",
    "        list of test trials to construct videos from; each element is index into  \n",
    "        test trials only; one of `trial_idxs` or `trials` must be \n",
    "        specified; `trials` takes precedence over `trial_idxs`\n",
    "    trials : :obj:`list`, optional\n",
    "        list of test trials to construct videos from; each element is index into all \n",
    "        possible trials (train, val, test); one of `trials` or `trial_idxs` must be \n",
    "        specified; `trials` takes precedence over `trial_idxs`\n",
    "    sess_idx : :obj:`int`, optional\n",
    "        session index into data generator\n",
    "    max_frames : :obj:`int`, optional\n",
    "        maximum number of frames to animate from a trial\n",
    "    frame_rate : :obj:`float`, optional\n",
    "        frame rate of saved movie\n",
    "    layout_pattern : :obj:`array-like`, optional\n",
    "        boolean entries specify which panels are used to display frames\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    n_labels = hparams['n_labels']\n",
    "    n_latents = hparams['n_ae_latents']\n",
    "    expt_name = hparams['experiment_name']\n",
    "\n",
    "    # set up models to fit\n",
    "    titles = ['Original']\n",
    "    for model in model_info:\n",
    "        titles.append(model['title'])\n",
    "        \n",
    "    # insert original video at front\n",
    "    model_info.insert(0, {'model_class': None})\n",
    "\n",
    "    ims_recon = [[] for _ in titles]\n",
    "    latents = [[] for _ in titles]\n",
    "    \n",
    "    if trial_idxs is None:\n",
    "        trial_idxs = [None] * len(trials)\n",
    "    if trials is None:\n",
    "        trials = [None] * len(trial_idxs)\n",
    "\n",
    "    for i, model in enumerate(model_info):\n",
    "\n",
    "        if i == 0:\n",
    "            continue\n",
    "            \n",
    "        # further specify model\n",
    "        version = model.get('version', 'best')\n",
    "        hparams['experiment_name'] = model.get('experiment_name', expt_name)\n",
    "        hparams['model_class'] = model['model_class']\n",
    "        model_ae, data_generator = get_best_model_and_data(hparams, None, version=version)\n",
    "\n",
    "        # get images\n",
    "        for trial_idx, trial in zip(trial_idxs, trials):\n",
    "\n",
    "            # get model inputs\n",
    "            ims_orig_pt, ims_orig_np, _, labels_pt, _, labels_2d_pt, _ = get_model_input(\n",
    "                data_generator, hparams, model_ae, trial_idx=trial_idx, trial=trial,\n",
    "                sess_idx=sess_idx, max_frames=max_frames, compute_latents=False, \n",
    "                compute_2d_labels=False)\n",
    "            \n",
    "            # get model outputs\n",
    "            ims_recon_tmp, latents_tmp = get_reconstruction(\n",
    "                model_ae, ims_orig_pt, labels=labels_pt, labels_2d=labels_2d_pt,\n",
    "                return_latents=True)\n",
    "            ims_recon[i].append(ims_recon_tmp)\n",
    "            latents[i].append(latents_tmp)\n",
    "                \n",
    "            # add a couple black frames to separate trials\n",
    "            final_trial = True\n",
    "            if (trial_idx is not None and (trial_idx != trial_idxs[-1])) or \\\n",
    "                    (trial is not None and (trial != trials[-1])):\n",
    "                final_trial = False\n",
    "\n",
    "            n_buffer = 5\n",
    "            if not final_trial:\n",
    "                _, n, y_p, x_p = ims_recon[i][-1].shape\n",
    "                ims_recon[i].append(np.zeros((n_buffer, n, y_p, x_p)))\n",
    "                latents[i].append(np.nan * np.zeros((n_buffer, n_latents)))\n",
    "\n",
    "            if i == 1:  # deal with original frames only once\n",
    "                ims_recon[0].append(ims_orig_np)\n",
    "                latents[0].append([])\n",
    "                # add a couple black frames to separate trials\n",
    "                if not final_trial:\n",
    "                    _, n, y_p, x_p = ims_recon[0][-1].shape\n",
    "                    ims_recon[0].append(np.zeros((n_buffer, n, y_p, x_p)))\n",
    "        \n",
    "    for i, (ims, zs) in enumerate(zip(ims_recon, latents)):\n",
    "        ims_recon[i] = np.concatenate(ims, axis=0)\n",
    "        latents[i] = np.concatenate(zs, axis=0)\n",
    "    \n",
    "    if layout_pattern is None:\n",
    "        if len(titles) < 4:\n",
    "            n_rows, n_cols = 1, len(titles)\n",
    "        elif len(titles) == 4:\n",
    "            n_rows, n_cols = 2, 2\n",
    "        elif len(titles) > 4:\n",
    "            n_rows, n_cols = 2, 3\n",
    "        else:\n",
    "            raise ValueError('too many models')\n",
    "    else:\n",
    "        assert np.sum(layout_pattern) == len(ims_recon)\n",
    "        n_rows, n_cols = layout_pattern.shape\n",
    "        count = 0\n",
    "        for pos_r in layout_pattern:\n",
    "            for pos_c in pos_r:\n",
    "                if not pos_c:\n",
    "                    ims_recon.insert(count, [])\n",
    "                    titles.insert(count, [])\n",
    "                count += 1\n",
    "\n",
    "    make_reconstruction_movie(\n",
    "        ims=ims_recon, titles=titles, n_rows=n_rows, n_cols=n_cols, \n",
    "        save_file=save_file, frame_rate=frame_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model info\n",
    "hparams = {\n",
    "    'data_dir': get_user_dir('data'),\n",
    "    'save_dir': get_user_dir('save'),\n",
    "    'n_labels': n_labels,\n",
    "    'n_ae_latents': n_latents + n_labels,\n",
    "    'experiment_name': None,\n",
    "    'model_type': 'conv',\n",
    "    'conditional_encoder': False,\n",
    "}\n",
    "\n",
    "# programmatically fill out other hparams options\n",
    "get_lab_example(hparams, lab, expt)\n",
    "\n",
    "# compare vae/ps-vae reconstructions\n",
    "model_info = [\n",
    "    {\n",
    "        'model_class': 'ps-vae',\n",
    "        'experiment_name': 'demo-run',\n",
    "        'title': 'PS-VAE (%i latents)' % (n_latents + n_labels),\n",
    "        'version': 0},\n",
    "    {\n",
    "        'model_class': 'vae',\n",
    "        'experiment_name': 'demo-run',\n",
    "        'title': 'VAE (%i latents)' % (n_latents + n_labels),\n",
    "        'version': 0},\n",
    "]\n",
    "\n",
    "save_file = os.path.join(\n",
    "    get_user_dir('fig'), lab, expt, animal, session, model_class, \n",
    "    'reconstructions_alpha={}_beta={}_gamma={}_rng={}_latents={}'.format(\n",
    "    best_alpha, best_beta, best_gamma, best_rng, n_latents))\n",
    "\n",
    "make_reconstruction_movie_wrapper(\n",
    "    hparams, save_file=save_file, trial_idxs=None, trials=label_recon_trials, \n",
    "    model_info=model_info, frame_rate=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "behavenet",
   "language": "python",
   "name": "behavenet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
