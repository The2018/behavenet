{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and preprocessing public IBL data\n",
    "\n",
    "This notebook will walk you through how to download public IBL data needed to fit the MSPS-VAE: raw mp4 videos and DLC traces. The notebook will then preprocess this data into the correct format for the Behavenet codebase.\n",
    "\n",
    "Note that the raw videos are large, 5-10GB each, and will thus take some time to download.\n",
    "\n",
    "You will first need to create a new conda environment and download the `ibllib` package that will facilitate data downloading. See the instructions [here](https://int-brain-lab.github.io/iblenv/public_docs/public_one.html). Activate the `ibllib` environment, then install the `h5py` package through conda:\n",
    "```\n",
    "(ibllib) $: conda install h5py\n",
    "```\n",
    "\n",
    "You will then need to run this notebook with the `ibllib` kernel so that you have access to the required code. You should see the current ipython kernel name in the upper right hand corner of this notebook. If it is not `ibllib` (for example it might be `Python 3`) then change it using the dropdown menus above: `Kernel > Change kernel > ibllib`. If you do not see `ibllib` as an option run the following command in the terminal - and make sure you have activated the `ibllib` conda environment first!\n",
    "\n",
    "```\n",
    "(ibllib) $: python -m ipykernel install --user --name ibllib\n",
    "```\n",
    "\n",
    "Notes: \n",
    "* you will need to update the local paths `data_path_raw` and `data_path_proc` below\n",
    "* ffmpeg is required to run the final function `test_hdf5_build`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from one.api import ONE\n",
    "\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "from ibl_utils.pipeline import PawProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------\n",
    "# set user-defined paths\n",
    "# ------------------------------------\n",
    "# where raw ibl data is stored - UPDATE THIS TO YOUR LOCAL PATH\n",
    "data_path_raw = '/media/mattw/data/TEST/raw_data/'\n",
    "# where processed behavenet hdf5 is stored - UPDATE THIS TO YOUR LOCAL PATH\n",
    "data_path_proc = '/media/mattw/data/TEST/data/'\n",
    "\n",
    "# connect to server\n",
    "one = ONE(\n",
    "    base_url='https://openalyx.internationalbrainlab.org', \n",
    "    cache_dir=data_path_raw,\n",
    "    password='international',\n",
    "    silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define public sessions used in ps-vae paper\n",
    "sessions = [        \n",
    "    # session 1\n",
    "#     {'eid': '89f0d6ff-69f4-45bc-b89e-72868abb042a', \n",
    "#      'lab': 'churchlandlab',\n",
    "#      'animal': 'CSHL047',\n",
    "#      'date': '2020-01-20',\n",
    "#      'number': '001'},\n",
    "    # session 2\n",
    "    {'eid': '4b7fbad4-f6de-43b4-9b15-c7c7ef44db4b', \n",
    "     'lab': 'churchlandlab',\n",
    "     'animal': 'CSHL049',\n",
    "     'date': '2020-01-08',\n",
    "     'number': '001'},\n",
    "    # session 3\n",
    "#     {'eid': 'aad23144-0e52-4eac-80c5-c4ee2decb198', \n",
    "#      'lab': 'cortexlab',\n",
    "#      'animal': 'KS023',\n",
    "#      'date': '2019-12-10',\n",
    "#      'number': '001'},\n",
    "    # session 4\n",
    "#     {'eid': '4ecb5d24-f5cc-402c-be28-9d0f7cb14b3a', \n",
    "#      'lab': 'hoferlab',\n",
    "#      'animal': 'SWC_043',\n",
    "#      'date': '2020-09-21',\n",
    "#      'number': '001'},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------\n",
    "# marker info\n",
    "# ------------------------------------\n",
    "# camera view to take frames from (paper uses left view)\n",
    "view = 'left'\n",
    "# likelihood threshold - markers with likelihoods below this threshold will be masked\n",
    "l_thresh = 0.9\n",
    "\n",
    "# ------------------------------------\n",
    "# hdf5 info\n",
    "# ------------------------------------\n",
    "# True to overwrite existing hdf5 file\n",
    "overwrite_hdf5 = True\n",
    "# xpix of final downsampled frames\n",
    "xpix = 192\n",
    "# ypix of final downsampled frames\n",
    "ypix = 192\n",
    "# number of contiguous frames per batch\n",
    "batch_size = 96\n",
    "# total number of batches\n",
    "n_batches = 150\n",
    "# batch_selection options:\n",
    "# 'me': batches with highest motion energy\n",
    "# 'random': random batches\n",
    "# None: use every time point in a batch\n",
    "batch_selection = 'me'  \n",
    "\n",
    "# loop over sessions\n",
    "for session in sessions:\n",
    "\n",
    "    # initialize class that handles video pipeline\n",
    "    vp = PawProcessor(one, view=view, **session)\n",
    "    print(vp)\n",
    "\n",
    "    # compute paths\n",
    "    vp.compute_paths(data_path_raw=data_path_raw)\n",
    "    vp.paths.data_path_proc = os.path.join(\n",
    "        data_path_proc, 'single-view', vp.lab, vp.animal, vp.session)\n",
    "    vp.paths.hdf5_file = os.path.join(vp.paths.data_path_proc, 'data.hdf5')\n",
    "    \n",
    "    # determine if we need to run pipeline\n",
    "    if os.path.exists(vp.paths.hdf5_file) and not overwrite_hdf5:\n",
    "        print('data.hdf5 file already exists at %s; skipping\\n\\n' % vp.paths.hdf5_file)\n",
    "        continue\n",
    "        \n",
    "    # download data from public server; will skip if data is already present\n",
    "    vp.download_data()\n",
    "\n",
    "    # load markers\n",
    "    vp.load_2d_markers(likelihood_thresh=l_thresh)\n",
    "\n",
    "    # load cv video capture objects\n",
    "    vp.load_video_cap()\n",
    "    \n",
    "    # find crop params to align videos to anatomical features\n",
    "    vp.find_crop_params()\n",
    "            \n",
    "    # update likelihoods to catch nan frames\n",
    "    for m in ['paw_l', 'paw_r']:\n",
    "        idxs_tmp = np.isnan(vp.markers.vals[m])[:, 0]\n",
    "        vp.markers.likelihoods[m][idxs_tmp] = 0\n",
    "        vp.markers.masks[m][idxs_tmp] = 0\n",
    "            \n",
    "    # update markers to reflect rescaling of view\n",
    "    if view == 'left':\n",
    "        # downsample markers from left view by a factor of 2\n",
    "        for m in vp.markers.vals.keys():\n",
    "            vp.markers.vals[m] /= 2\n",
    "\n",
    "    # build hdf5 file\n",
    "    print('constructing hdf5 file at %s' % vp.paths.hdf5_file)\n",
    "#     vp.build_hdf5(\n",
    "#         hdf5_file=vp.paths.hdf5_file, batch_size=batch_size, xpix=xpix, ypix=ypix,\n",
    "#         n_batches=n_batches, batch_selection=batch_selection)\n",
    "\n",
    "    # output test video as a sanity check\n",
    "    print('testing hdf5 file at %s' % vp.paths.hdf5_file)\n",
    "    save_file = os.path.join(vp.paths.data_path_proc, 'test-batch_hdf5.mp4')\n",
    "    idxs = [0, 49, 99, 149]\n",
    "    data_dict = vp.test_hdf5_build(vp.paths.hdf5_file, idxs=idxs, save_file=save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iblenv",
   "language": "python",
   "name": "iblenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
